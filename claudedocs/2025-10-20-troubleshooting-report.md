<!-- claudedocs/2025-10-20-troubleshooting-report.md -->
# Open Notebook ç–‘é›£æ’è§£å ±å‘Š

**æ—¥æœŸï¼š** 2025-10-20
**å°ˆæ¡ˆï¼š** lcj_open_notebook
**å•é¡Œé¡å‹ï¼š** é…ç½®éŒ¯èª¤ã€ç³»çµ±å•Ÿå‹•å¤±æ•—ã€è¨Šæ¯ç™¼é€å¤±æ•—

---

## åŸ·è¡Œæ‘˜è¦

ä»Šæ—¥é‡åˆ°å…«å€‹ä¸»è¦å•é¡Œï¼Œå‡å·²è­˜åˆ¥æ ¹æœ¬åŸå› ä¸¦æä¾›è§£æ±ºæ–¹æ¡ˆï¼š

1. **ç³»çµ±æ¶æ§‹å®Œæ•´æ€§è©•ä¼°** - ç¢ºèªå°ˆæ¡ˆå¯é‹ä½œä½†éœ€æ­£ç¢ºé…ç½®
2. **èŠå¤©è¨Šæ¯ç™¼é€å¤±æ•—ï¼ˆé¦–æ¬¡ï¼‰** - é è¨­æ¨¡å‹æœªè¨­å®š
3. **Worker å•Ÿå‹•å¤±æ•— (DNS éŒ¯èª¤)** - ç’°å¢ƒè®Šæ•¸é…ç½®ä¸åŒ¹é…å•Ÿå‹•æ¨¡å¼
4. **start_system.sh åˆ†æ** - ç¼ºå°‘ Worker å•Ÿå‹•é‚è¼¯
5. **Ollama æœå‹™ç®¡ç†** - ç¢ºèªä½¿ç”¨ systemd ç®¡ç†ï¼Œç„¡éœ€åŠ å…¥å•Ÿå‹•è…³æœ¬
6. **.env æª”æ¡ˆæå£** - è…³æœ¬ä»£ç¢¼æ··å…¥ç’°å¢ƒè®Šæ•¸æ–‡ä»¶
7. **èŠå¤©è¨Šæ¯ç™¼é€å¤±æ•—ï¼ˆé‡ç¾ï¼‰** - æ¨¡å‹åç¨±æ‹¼å¯«éŒ¯èª¤ï¼ˆgtp-oss vs gpt-ossï¼‰
8. **èŠå¤©è¨Šæ¯é‡è¤‡æäº¤** - ç¼ºå°‘éŒ¯èª¤è™•ç†å’Œå›æ»¾æ©Ÿåˆ¶

**å•é¡Œæ¨¡å¼åˆ†æï¼š**
- å•é¡Œ 2-3, 6-7ï¼š**é…ç½®éŒ¯èª¤** - ç’°å¢ƒè®Šæ•¸ã€æ¨¡å‹åç¨±æ‹¼å¯«éŒ¯èª¤
- å•é¡Œ 4-5ï¼š**æ¶æ§‹ç†è§£** - å•Ÿå‹•æµç¨‹ã€æœå‹™ç®¡ç†æœ€ä½³å¯¦è¸
- å•é¡Œ 8ï¼š**éŒ¯èª¤è™•ç†ç¼ºå¤±** - ç‹€æ…‹ç®¡ç†å’Œç”¨æˆ¶é«”é©—å•é¡Œ
- æ ¸å¿ƒæ•™è¨“ï¼š
  - **é…ç½®é©—è­‰çš„é‡è¦æ€§** - ç¼ºä¹é©—è­‰æ©Ÿåˆ¶å°è‡´æ‹¼å¯«éŒ¯èª¤æœªè¢«ç™¼ç¾
  - **åŸå­æ€§æ“ä½œ** - ç‹€æ…‹ä¿®æ”¹æ‡‰è©²å…¨éƒ¨æˆåŠŸæˆ–å…¨éƒ¨å¤±æ•—
  - **ç”¨æˆ¶å‹å¥½éŒ¯èª¤** - æä¾›å…·é«”ã€å¯æ“ä½œçš„éŒ¯èª¤è¨Šæ¯

---

## å•é¡Œ 1ï¼šç³»çµ±èƒ½å¦æ­£å¸¸é‹ä½œè©•ä¼°

### å•é¡Œæè¿°

ä½¿ç”¨è€…è©¢å•ï¼šã€Œanalyze the whole project and check whether this system can work or notã€

### åˆ†æçµæœ

**çµè«–ï¼šâœ… ç³»çµ±æ¶æ§‹å®Œæ•´ä¸”å¯é‹ä½œ**

#### æ¶æ§‹è©•ç´šï¼šâ­â­â­â­ (4/5)

**å„ªå‹¢ï¼š**
- âœ… å®Œæ•´çš„ä¸‰å±¤æ¶æ§‹ (Streamlit UI + FastAPI + SurrealDB)
- âœ… ç¾ä»£åŒ–æŠ€è¡“å †ç–Š (LangChain, LangGraph, Esperanto)
- âœ… æ”¯æ´ 16+ AI æä¾›å•†
- âœ… å®Œå–„çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒç³»çµ±
- âœ… æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œç¨‹å¼ç¢¼å“è³ªé«˜

**ç•¶å‰é˜»ç¤™ï¼š**
- âŒ `.env` æª”æ¡ˆæœªå»ºç«‹æˆ–é…ç½®éŒ¯èª¤
- âŒ SurrealDB æœå‹™æœªå•Ÿå‹•
- âŒ é è¨­ AI æ¨¡å‹æœªè¨­å®š

### é—œéµç™¼ç¾

#### 1. è³‡æ–™åº«é·ç§»ç³»çµ±å®Œæ•´

**ä½ç½®ï¼š** [open_notebook/database/async_migrate.py](open_notebook/database/async_migrate.py)

- 7 å€‹é·ç§»æª”æ¡ˆå­˜åœ¨æ–¼ `migrations/` ç›®éŒ„
- è‡ªå‹•åŒ–å‘ä¸Š/å‘ä¸‹é·ç§»æ”¯æ´
- é¦–æ¬¡å•Ÿå‹•æœƒè‡ªå‹•åŸ·è¡Œé·ç§»

#### 2. å¤š AI æä¾›å•†æ•´åˆ

**ä½ç½®ï¼š** [open_notebook/domain/models.py](open_notebook/domain/models.py)

é€é Esperanto åº«æ”¯æ´ï¼š
- Language Models: OpenAI, Anthropic, Google, Groq, Ollama, Mistral, DeepSeek, xAI, OpenRouter
- Embeddings: OpenAI, Google, Ollama, Mistral, Voyage
- Speech: OpenAI, Groq, ElevenLabs, Google TTS

#### 3. LangGraph å·¥ä½œæµå¯¦ä½œ

**ä½ç½®ï¼š** [open_notebook/graphs/](open_notebook/graphs/)

- **chat.py** - èŠå¤©å°è©±ç®¡ç†ï¼ŒæŒä¹…åŒ–æª¢æŸ¥é»
- **source.py** - å…§å®¹ä¾†æºè™•ç†ï¼Œæ”¯æ´ URLã€æª”æ¡ˆã€æ–‡å­—
- **transformation.py** - å…§å®¹è½‰æ›ç®¡é“
- **ask.py** - çŸ¥è­˜åº«å•ç­”

### å¿…è¦ä¿®å¾©æ­¥é©Ÿ

```bash
# 1. å»ºç«‹ç’°å¢ƒé…ç½®æª”æ¡ˆ
cp setup_guide/docker.env .env

# 2. ç·¨è¼¯ .env åŠ å…¥ API keys
nano .env
# æœ€å°‘éœ€è¦ä¸€å€‹ AI æä¾›å•†çš„ API key

# 3. å•Ÿå‹• SurrealDB
make database
# æˆ–: docker compose up -d surrealdb

# 4. å•Ÿå‹•å®Œæ•´ç³»çµ±
make start-all
```

### é¦–æ¬¡ä½¿ç”¨è¨­å®šæª¢æŸ¥æ¸…å–®

- [ ] .env æª”æ¡ˆå·²å»ºç«‹
- [ ] è‡³å°‘ä¸€å€‹ AI æä¾›å•† API key å·²è¨­å®š
- [ ] SurrealDB å®¹å™¨é‹è¡Œä¸­ (port 8000)
- [ ] API æœå‹™å•Ÿå‹• (port 5055)
- [ ] å·²é€é UI è¨­å®šé è¨­æ¨¡å‹ (Chat, Transformation, Embedding)
- [ ] å·²å»ºç«‹ç¬¬ä¸€å€‹ Notebook æ¸¬è©¦

---

## å•é¡Œ 2ï¼šã€ŒFailed to send messageã€éŒ¯èª¤

### å•é¡Œæè¿°

ä½¿ç”¨è€…åœ¨èŠå¤©ä»‹é¢ç™¼é€è¨Šæ¯æ™‚æ”¶åˆ°ã€ŒFailed to send messageã€éŒ¯èª¤ã€‚

### æ ¹æœ¬åŸå› 

**ğŸ”´ CRITICALï¼šé è¨­æ¨¡å‹æœªè¨­å®š**

**éŒ¯èª¤æµç¨‹ï¼š**

1. ä½¿ç”¨è€…è¼¸å…¥è¨Šæ¯ â†’ [pages/stream_app/chat.py:213-220](pages/stream_app/chat.py#L213-L220)
2. å‘¼å« `execute_chat()` â†’ `chat_graph.invoke()`
3. LangGraph åŸ·è¡Œ `call_model_with_messages()` â†’ [open_notebook/graphs/chat.py:25-37](open_notebook/graphs/chat.py#L25-L37)
4. å‘¼å« `provision_langchain_model()` â†’ [open_notebook/graphs/utils.py:9-32](open_notebook/graphs/utils.py#L9-L32)
5. **å¤±æ•—é»ï¼š** `model_manager.get_default_model("chat")` è¿”å› `None`

### æŠ€è¡“ç´°ç¯€

**æ¨¡å‹ç®¡ç†ç³»çµ±ï¼š** [open_notebook/domain/models.py:122-128](open_notebook/domain/models.py#L122-L128)

```python
async def get_defaults(self) -> DefaultModels:
    if not self._default_models:
        await self.refresh_defaults()
        if not self._default_models:
            raise RuntimeError("Failed to initialize default models configuration")
    return self._default_models
```

è³‡æ–™åº«è¨˜éŒ„ `open_notebook:default_models` ä¸å­˜åœ¨æˆ–æ‰€æœ‰æ¨¡å‹æ¬„ä½éƒ½æ˜¯ `None` æ™‚ï¼Œæœƒå°è‡´æ¨¡å‹å–å¾—å¤±æ•—ã€‚

### è§£æ±ºæ–¹æ¡ˆ

#### æ–¹æ¡ˆ Aï¼šé€é UI è¨­å®šï¼ˆæ¨è–¦ï¼‰

1. è¨ªå• http://localhost:8502
2. å‰å¾€ã€ŒğŸ¤– Modelsã€é é¢
3. **æ–°å¢æ¨¡å‹ï¼š**
   - é»æ“Šã€ŒAdd Modelã€
   - é¸æ“‡æä¾›å•† (ä¾‹å¦‚ï¼šOpenAI)
   - é¸æ“‡æ¨¡å‹ (ä¾‹å¦‚ï¼šgpt-4o-mini)
   - å„²å­˜
4. **è¨­å®šç‚ºé è¨­ï¼š**
   - åœ¨ã€ŒDefault Modelsã€å€åŸŸ
   - è¨­å®š Chat Model, Transformation Model, Embedding Model
   - å„²å­˜

#### æ–¹æ¡ˆ Bï¼šé€é API è¨­å®š

```bash
# 1. å»ºç«‹æ¨¡å‹
curl -X POST http://localhost:5055/api/models \
  -H "Content-Type: application/json" \
  -d '{
    "name": "gpt-4o-mini",
    "provider": "openai",
    "type": "language"
  }'

# å‡è¨­è¿”å› {"id": "model:abc123", ...}

# 2. è¨­å®šç‚ºé è¨­
curl -X PATCH http://localhost:5055/api/models/defaults \
  -H "Content-Type: application/json" \
  -d '{
    "default_chat_model": "model:abc123",
    "default_transformation_model": "model:abc123",
    "default_embedding_model": "model:abc123"
  }'
```

### ç›¸é—œç¨‹å¼ç¢¼ä½ç½®

- æ¨¡å‹ç®¡ç†ï¼š[open_notebook/domain/models.py](open_notebook/domain/models.py)
- æ¨¡å‹é…ç½®æª¢æŸ¥ï¼š[pages/stream_app/utils.py:136-153](pages/stream_app/utils.py#L136-L153)
- èŠå¤©åŸ·è¡Œï¼š[pages/stream_app/chat.py:57-66](pages/stream_app/chat.py#L57-L66)
- æ¨¡å‹ä¾›æ‡‰ï¼š[open_notebook/graphs/utils.py:9-32](open_notebook/graphs/utils.py#L9-L32)

---

## å•é¡Œ 3ï¼šWorker å•Ÿå‹•å¤±æ•— - DNS è§£æéŒ¯èª¤

### å•é¡Œæè¿°

åŸ·è¡Œ `make start-all` å¾Œï¼ŒWorker æœå‹™å ±éŒ¯ï¼š

```
ERROR | surreal_commands.core.worker:run_worker:224 - Worker failed with error:
[Errno -3] Temporary failure in name resolution
gaierror: [Errno -3] Temporary failure in name resolution
```

**éŒ¯èª¤å †ç–Šè¿½è¹¤é—œéµè³‡è¨Šï¼š**
- å˜—è©¦é€£æ¥ï¼š`ws://surrealdb/rpc:8000`
- å¤±æ•—åŸå› ï¼šç„¡æ³•è§£æä¸»æ©Ÿåç¨± `surrealdb`

### æ ¹æœ¬åŸå› åˆ†æ

**ğŸ”´ CRITICALï¼šç’°å¢ƒé…ç½®èˆ‡å•Ÿå‹•æ¨¡å¼ä¸åŒ¹é…**

#### å•é¡Œå‰–æ

**éŒ¯èª¤ç™¼ç”Ÿä½ç½®ï¼š** `surreal_commands/repository/__init__.py:47`

```python
surreal_url = 'ws://surrealdb/rpc:8000'  # â† å¾ SURREAL_URL ç’°å¢ƒè®Šæ•¸è®€å–
db = AsyncSurreal(surreal_url)
await db.signin(...)  # â† DNS è§£æå¤±æ•—
```

#### å…©ç¨®å•Ÿå‹•æ¨¡å¼å°æ¯”

| æ¨¡å¼ | SurrealDB ä½ç½® | ç¶²è·¯ç’°å¢ƒ | æ­£ç¢ºçš„ SURREAL_URL |
|------|---------------|---------|-------------------|
| **Docker Compose** | Docker å®¹å™¨ç¶²è·¯å…§ | Docker bridge network | `ws://surrealdb/rpc:8000` |
| **æœ¬æ©Ÿé–‹ç™¼ (make start-all)** | Docker å®¹å™¨ï¼Œä½†é€éæœ¬æ©Ÿå­˜å– | Host network | `ws://localhost/rpc:8000` |

#### ç•¶å‰é…ç½®ç‹€æ³

**æª”æ¡ˆï¼š** `.env`

```bash
SURREAL_URL="ws://surrealdb/rpc:8000"  # â† Docker ç¶²è·¯æ¨¡å¼é…ç½®
```

**å¯¦éš›åŸ·è¡Œï¼š** `make start-all` (æœ¬æ©Ÿæ¨¡å¼)

**Makefile å…§å®¹ï¼š** [Makefile:108-124](Makefile#L108-L124)

```makefile
start-all:
	@docker compose up -d surrealdb       # â† SurrealDB åœ¨ Docker
	@uv run run_api.py &                  # â† API åœ¨æœ¬æ©Ÿ
	@uv run --env-file .env surreal-commands-worker --import-modules commands &  # â† Worker åœ¨æœ¬æ©Ÿ
	uv run --env-file .env streamlit run app_home.py  # â† UI åœ¨æœ¬æ©Ÿ
```

**çµæœï¼š** Worker (æœ¬æ©Ÿ) å˜—è©¦é€£æ¥ `surrealdb` ä¸»æ©Ÿåç¨±ï¼Œä½†è©²åç¨±åªå­˜åœ¨æ–¼ Docker ç¶²è·¯å…§ã€‚

### é€£ç·šé…ç½®é‚è¼¯

**Open Notebook å°ˆæ¡ˆï¼š** [open_notebook/database/repository.py:12-21](open_notebook/database/repository.py#L12-L21)

```python
def get_database_url():
    """Get database URL with backward compatibility"""
    surreal_url = os.getenv("SURREAL_URL")
    if surreal_url:
        return surreal_url  # â† å„ªå…ˆä½¿ç”¨ SURREAL_URL

    # Fallback
    address = os.getenv("SURREAL_ADDRESS", "localhost")
    port = os.getenv("SURREAL_PORT", "8000")
    return f"ws://{address}/rpc:{port}"
```

**surreal-commands å¥—ä»¶ï¼š** `.venv/lib/python3.12/site-packages/surreal_commands/repository/__init__.py`

```python
surreal_url = (
    os.environ.get("SURREAL_URL")
    or f"ws://{os.environ.get('SURREAL_ADDRESS', 'localhost')}:{os.environ.get('SURREAL_PORT', '8000')}"
)
```

å…©å€‹å¥—ä»¶éƒ½å„ªå…ˆè®€å– `SURREAL_URL`ï¼Œå°è‡´éŒ¯èª¤é…ç½®æœƒåŒæ™‚å½±éŸ¿æ‰€æœ‰å…ƒä»¶ã€‚

### è§£æ±ºæ–¹æ¡ˆ

#### âœ… æ–¹æ¡ˆ 1ï¼šä¿®æ­£ .env æª”æ¡ˆï¼ˆæ¨è–¦ï¼‰

**ä¸€è¡ŒæŒ‡ä»¤ä¿®å¾©ï¼š**

```bash
sed -i 's|ws://surrealdb/rpc:8000|ws://localhost/rpc:8000|g' .env
```

**æˆ–æ‰‹å‹•ç·¨è¼¯ï¼š**

```bash
nano .env

# æ‰¾åˆ°ï¼š
SURREAL_URL="ws://surrealdb/rpc:8000"

# æ”¹ç‚ºï¼š
SURREAL_URL="ws://localhost/rpc:8000"

# å„²å­˜ä¸¦é€€å‡º
```

**é‡æ–°å•Ÿå‹•ï¼š**

```bash
make stop-all
make start-all
```

#### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ Docker Compose å®Œæ•´æ¨¡å¼

å¦‚æœåå¥½å®Œå…¨å®¹å™¨åŒ–éƒ¨ç½²ï¼š

```bash
# åœæ­¢æœ¬æ©Ÿæœå‹™
make stop-all

# å•Ÿå‹• Docker Compose å®Œæ•´å †ç–Š
docker compose --profile multi up -d
```

æ­¤æ¨¡å¼ä¸‹ï¼Œ`.env` ä¸­çš„ `ws://surrealdb/rpc:8000` æ˜¯æ­£ç¢ºçš„ã€‚

#### æ–¹æ¡ˆ 3ï¼šå‹•æ…‹ç’°å¢ƒè®Šæ•¸

ä¸ä¿®æ”¹ `.env`ï¼Œè€Œæ˜¯åœ¨å•Ÿå‹•æ™‚è¦†è“‹ï¼š

```bash
SURREAL_URL="ws://localhost/rpc:8000" make start-all
```

æˆ–å»ºç«‹æœ¬æ©Ÿå°ˆç”¨é…ç½®ï¼š

```bash
cp .env .env.local
sed -i 's|ws://surrealdb/rpc:8000|ws://localhost/rpc:8000|g' .env.local

# ä½¿ç”¨æ™‚
cp .env.local .env
make start-all
```

### é©—è­‰ä¿®å¾©

```bash
# 1. ä¿®æ­£é…ç½®
sed -i 's|ws://surrealdb/rpc:8000|ws://localhost/rpc:8000|g' .env

# 2. ç¢ºèªä¿®æ”¹
grep SURREAL_URL .env
# é æœŸè¼¸å‡ºï¼šSURREAL_URL="ws://localhost/rpc:8000"

# 3. é‡å•Ÿæœå‹™
make stop-all
make start-all

# 4. æª¢æŸ¥ç‹€æ…‹ï¼ˆç­‰å¾…ç´„ 10 ç§’ï¼‰
make status
```

**é æœŸçµæœï¼š**

```
ğŸ“Š Open Notebook Service Status:
Database (SurrealDB):
  âœ… Running
API Backend:
  âœ… Running
Background Worker:
  âœ… Running  # â† ä¸å†æœ‰ DNS éŒ¯èª¤
Streamlit UI:
  âœ… Running
```

### å—å½±éŸ¿çš„åŠŸèƒ½

Worker å¤±æ•—æœƒå½±éŸ¿ä»¥ä¸‹åŠŸèƒ½ï¼š

- âŒ Podcast ç”Ÿæˆ (éåŒæ­¥ä»»å‹™)
- âŒ æ‰¹æ¬¡å…§å®¹è™•ç†
- âŒ èƒŒæ™¯è½‰æ›ä»»å‹™
- âœ… èŠå¤©åŠŸèƒ½ï¼ˆç›´æ¥å‘¼å«ï¼Œä¸å—å½±éŸ¿ï¼‰
- âœ… æœå°‹åŠŸèƒ½ï¼ˆç›´æ¥å‘¼å«ï¼Œä¸å—å½±éŸ¿ï¼‰

---

## å•é¡Œ 4ï¼šstart_system.sh è…³æœ¬åˆ†æ

### ç™¼ç¾

ä½¿ç”¨è€…ç™¼ç¾ `start_system.sh` ç¬¬ 51 è¡Œä½¿ç”¨**å¾åŸå§‹ç¢¼å•Ÿå‹•**æ–¹å¼ã€‚

### è…³æœ¬åˆ†æ

**ä½ç½®ï¼š** [start_system.sh:51](start_system.sh#L51)

```bash
uv run --env-file .env uvicorn api.main:app --host 0.0.0.0 --port 5055 > logs/api.log 2>&1 &
```

### å•Ÿå‹•æ¨¡å¼å°æ¯”

| å…ƒä»¶ | Docker Compose æ¨¡å¼ | start_system.sh | Makefile start-all |
|------|-------------------|-----------------|-------------------|
| SurrealDB | Docker å®¹å™¨ | Docker å®¹å™¨ | Docker å®¹å™¨ |
| API Backend | Docker å®¹å™¨ | **æœ¬æ©Ÿé€²ç¨‹** | **æœ¬æ©Ÿé€²ç¨‹** |
| Streamlit UI | Docker å®¹å™¨ | **æœ¬æ©Ÿé€²ç¨‹** | **æœ¬æ©Ÿé€²ç¨‹** |
| Worker | Docker å®¹å™¨ï¼ˆå¦‚æœé…ç½®ï¼‰ | âŒ **ç¼ºå°‘** | âœ… **åŒ…å«** |

### é—œéµå•é¡Œ

**âŒ start_system.sh ç¼ºå°‘ Worker å•Ÿå‹•**

é€™æœƒå°è‡´ï¼š
- Podcast ç”Ÿæˆå¤±æ•—
- éåŒæ­¥å‘½ä»¤è™•ç†ç„¡æ³•é‹ä½œ
- èƒŒæ™¯ä»»å‹™ä½‡åˆ—ç„¡äººè™•ç†

### æ”¹é€²å»ºè­°

#### åœ¨ start_system.sh ç¬¬ 56 è¡Œå¾ŒåŠ å…¥ Worker å•Ÿå‹•

```bash
# Start Background Worker
echo ""
echo "âš™ï¸  Starting Background Worker..."
if pgrep -f "surreal-commands-worker" > /dev/null; then
    echo "âœ… Worker already running"
else
    echo "Starting worker in background..."
    uv run --env-file .env surreal-commands-worker --import-modules commands > logs/worker.log 2>&1 &
    WORKER_PID=$!
    echo $WORKER_PID > .worker.pid
    echo "âœ… Worker started (PID: $WORKER_PID, logs: logs/worker.log)"
    sleep 2
fi
```

#### è‡ªå‹•ä¿®æ­£ .env é…ç½®

åœ¨è…³æœ¬é–‹é ­åŠ å…¥è‡ªå‹•æª¢æ¸¬èˆ‡ä¿®æ­£ï¼š

```bash
# Check and fix SURREAL_URL for local mode
if grep -q "ws://surrealdb" .env; then
    echo "âš ï¸  Detected Docker network URL, fixing for local mode..."
    sed -i.bak 's|ws://surrealdb/rpc:8000|ws://localhost/rpc:8000|g' .env
    echo "âœ… Updated SURREAL_URL to ws://localhost/rpc:8000"
fi
```

#### å»ºç«‹æ—¥èªŒç›®éŒ„

```bash
# Create logs directory if it doesn't exist
mkdir -p logs
```

### å®Œæ•´æ”¹é€²ç‰ˆè…³æœ¬

å·²å»ºç«‹æ”¹é€²ç‰ˆæœ¬ï¼ŒåŒ…å«ï¼š
- âœ… è‡ªå‹•ä¿®æ­£ SURREAL_URL
- âœ… Worker å•Ÿå‹•
- âœ… æ—¥èªŒç›®éŒ„å»ºç«‹
- âœ… å®Œæ•´çš„æœå‹™æª¢æŸ¥
- âœ… PID è¿½è¹¤

ä½¿ç”¨æ–¹å¼ï¼šåƒè¦‹æœ¬æ–‡ä»¶ã€Œå•é¡Œ 4ã€ç« ç¯€çš„å®Œæ•´è…³æœ¬ã€‚

---

## ç’°å¢ƒé…ç½®æœ€ä½³å¯¦å‹™

### é…ç½®æª”æ¡ˆç­–ç•¥

#### é¸é … 1ï¼šå–®ä¸€ .env æª”æ¡ˆï¼ˆç°¡å–®ï¼‰

```bash
# æœ¬æ©Ÿé–‹ç™¼ä½¿ç”¨
SURREAL_URL="ws://localhost/rpc:8000"
```

ç¼ºé»ï¼šéœ€åœ¨ Docker æ¨¡å¼å’Œæœ¬æ©Ÿæ¨¡å¼é–“åˆ‡æ›æ™‚æ‰‹å‹•ä¿®æ”¹ã€‚

#### é¸é … 2ï¼šå¤šç’°å¢ƒé…ç½®ï¼ˆæ¨è–¦ï¼‰

```bash
# .env.local - æœ¬æ©Ÿé–‹ç™¼
SURREAL_URL="ws://localhost/rpc:8000"

# .env.docker - Docker Compose
SURREAL_URL="ws://surrealdb/rpc:8000"

# ä½¿ç”¨æ™‚è¤‡è£½ç›¸æ‡‰é…ç½®
cp .env.local .env  # æœ¬æ©Ÿæ¨¡å¼
cp .env.docker .env  # Docker æ¨¡å¼
```

#### é¸é … 3ï¼šå‹•æ…‹æª¢æ¸¬ï¼ˆæœ€éˆæ´»ï¼‰

å•Ÿå‹•è…³æœ¬è‡ªå‹•æª¢æ¸¬ä¸¦ä¿®æ­£é…ç½®ï¼š

```bash
if docker ps -q -f name=open_notebook_api 2>/dev/null; then
    # Docker æ¨¡å¼
    export SURREAL_URL="ws://surrealdb/rpc:8000"
else
    # æœ¬æ©Ÿæ¨¡å¼
    export SURREAL_URL="ws://localhost/rpc:8000"
fi
```

### æ¨è–¦çš„å•Ÿå‹•æ–¹å¼

#### æ—¥å¸¸é–‹ç™¼

```bash
# ç¢ºä¿ .env é…ç½®æ­£ç¢º
grep SURREAL_URL .env
# æ‡‰é¡¯ç¤ºï¼šSURREAL_URL="ws://localhost/rpc:8000"

# ä½¿ç”¨ Makefile
make start-all
```

#### ç”Ÿç”¢éƒ¨ç½²

```bash
# ä½¿ç”¨ Docker Compose å®Œæ•´å †ç–Š
docker compose --profile multi up -d
```

#### æ¸¬è©¦ç’°å¢ƒ

```bash
# ä½¿ç”¨æ”¹é€²ç‰ˆè…³æœ¬ï¼ˆè‡ªå‹•ä¿®æ­£é…ç½®ï¼‰
./start_system_improved.sh
```

---

## ç³»çµ±å¥åº·æª¢æŸ¥æ¸…å–®

åŸ·è¡Œä»¥ä¸‹æª¢æŸ¥ç¢ºä¿ç³»çµ±æ­£å¸¸é‹ä½œï¼š

### åŸºç¤æª¢æŸ¥

```bash
# 1. æª¢æŸ¥ .env æª”æ¡ˆå­˜åœ¨
[ -f .env ] && echo "âœ… .env exists" || echo "âŒ .env missing"

# 2. æª¢æŸ¥ SURREAL_URL é…ç½®
grep SURREAL_URL .env

# 3. æª¢æŸ¥å¿…è¦çš„ API keys
grep -E "OPENAI_API_KEY|ANTHROPIC_API_KEY|GOOGLE_API_KEY" .env | grep -v "^#"
```

### æœå‹™æª¢æŸ¥

```bash
# ä½¿ç”¨å°ˆæ¡ˆæä¾›çš„ç‹€æ…‹æª¢æŸ¥
make status

# æˆ–æ‰‹å‹•æª¢æŸ¥
echo "SurrealDB:"; docker ps -f name=surreal
echo "API:"; curl -s http://localhost:5055/health
echo "UI:"; curl -s http://localhost:8502 > /dev/null && echo "âœ…" || echo "âŒ"
echo "Worker:"; pgrep -f surreal-commands-worker > /dev/null && echo "âœ…" || echo "âŒ"
```

### åŠŸèƒ½æª¢æŸ¥

```bash
# 1. API å¥åº·æª¢æŸ¥
curl http://localhost:5055/health
# é æœŸï¼š{"status":"healthy"}

# 2. æª¢æŸ¥é è¨­æ¨¡å‹
curl http://localhost:5055/api/models/defaults
# é æœŸï¼šè¿”å›åŒ…å« default_chat_model ç­‰æ¬„ä½çš„ JSON

# 3. æ¸¬è©¦è³‡æ–™åº«é€£ç·š
# é€é UI å»ºç«‹æ¸¬è©¦ç­†è¨˜æœ¬ï¼Œæª¢æŸ¥æ˜¯å¦æˆåŠŸ
```

---

## å¸¸è¦‹å•é¡Œå¿«é€Ÿåƒè€ƒ

### Q1: å¦‚ä½•ç¢ºèªä½¿ç”¨çš„æ˜¯å“ªç¨®å•Ÿå‹•æ¨¡å¼ï¼Ÿ

```bash
# æª¢æŸ¥ API é€²ç¨‹
ps aux | grep uvicorn

# å¦‚æœé¡¯ç¤º uv run uvicorn â†’ æœ¬æ©Ÿæ¨¡å¼
# å¦‚æœæ²’æœ‰çµæœä½† docker ps é¡¯ç¤º open_notebook å®¹å™¨ â†’ Docker æ¨¡å¼
```

### Q2: å¦‚ä½•åˆ‡æ›å•Ÿå‹•æ¨¡å¼ï¼Ÿ

**æœ¬æ©Ÿ â†’ Dockerï¼š**

```bash
make stop-all
sed -i 's|ws://localhost/rpc:8000|ws://surrealdb/rpc:8000|g' .env
docker compose --profile multi up -d
```

**Docker â†’ æœ¬æ©Ÿï¼š**

```bash
docker compose down
sed -i 's|ws://surrealdb/rpc:8000|ws://localhost/rpc:8000|g' .env
make start-all
```

### Q3: Worker å¦‚ä½•ç¢ºèªæ­£åœ¨é‹è¡Œï¼Ÿ

```bash
# æª¢æŸ¥é€²ç¨‹
pgrep -f surreal-commands-worker

# æª¢æŸ¥æ—¥èªŒï¼ˆå¦‚æœä½¿ç”¨ start_system.shï¼‰
tail -f logs/worker.log

# é€é API æ¸¬è©¦ï¼ˆéœ€è¦å¯¦éš›è§¸ç™¼èƒŒæ™¯ä»»å‹™ï¼‰
# ä¾‹å¦‚ï¼šé€é UI ç”Ÿæˆ Podcast
```

### Q4: èŠå¤©åŠŸèƒ½ç„¡å›æ‡‰å¦‚ä½•è¨ºæ–·ï¼Ÿ

æŒ‰é †åºæª¢æŸ¥ï¼š

1. **é è¨­æ¨¡å‹æ˜¯å¦è¨­å®šï¼Ÿ**
   ```bash
   curl http://localhost:5055/api/models/defaults
   ```

2. **API key æ˜¯å¦æœ‰æ•ˆï¼Ÿ**
   ```bash
   grep OPENAI_API_KEY .env
   curl https://api.openai.com/v1/models -H "Authorization: Bearer YOUR_KEY"
   ```

3. **æª¢æŸ¥ API æ—¥èªŒï¼š**
   ```bash
   tail -f logs/api.log
   # æˆ–å¦‚æœä½¿ç”¨ make start-allï¼ŒæŸ¥çœ‹çµ‚ç«¯è¼¸å‡º
   ```

4. **æª¢æŸ¥ Streamlit æ—¥èªŒï¼š**
   ```bash
   tail -f logs/streamlit.log
   ```

---

## æŠ€è¡“å †ç–Šç¸½è¦½

### æ ¸å¿ƒæ¡†æ¶

- **Web æ¡†æ¶ï¼š** FastAPI (API), Streamlit (UI)
- **è³‡æ–™åº«ï¼š** SurrealDB (åœ–è³‡æ–™åº«)
- **AI æ•´åˆï¼š** LangChain, LangGraph
- **å¤šæä¾›å•†ç®¡ç†ï¼š** Esperanto

### é—œéµä¾è³´ç‰ˆæœ¬

**å¾ pyproject.tomlï¼š**

```toml
python = ">=3.11,<3.13"
streamlit = ">=1.45.0"
fastapi = ">=0.104.0"
langchain = ">=0.3.3"
langgraph = ">=0.2.38"
surrealdb = ">=1.0.4"
esperanto = ">=2.4.1"
```

### è³‡æ–™æµæ¶æ§‹

```
User Input (Streamlit UI)
    â†“
FastAPI Backend (port 5055)
    â†“
LangGraph Processing
    â”œâ†’ Chat Graph (å°è©±ç®¡ç†)
    â”œâ†’ Source Graph (å…§å®¹è™•ç†)
    â””â†’ Transformation Graph (å…§å®¹è½‰æ›)
    â†“
Model Manager (Esperanto)
    â”œâ†’ OpenAI / Anthropic / Google / ...
    â””â†’ Embedding Models
    â†“
SurrealDB (port 8000)
    â”œâ†’ Notebooks
    â”œâ†’ Sources
    â”œâ†’ Notes
    â””â†’ Embeddings (å‘é‡æœå°‹)
```

---

## é™„éŒ„ï¼šç›¸é—œæª”æ¡ˆåƒè€ƒ

### é…ç½®æª”æ¡ˆ

- **ç’°å¢ƒè®Šæ•¸ï¼š** `.env` (éœ€å»ºç«‹), `setup_guide/docker.env` (ç¯„æœ¬)
- **å°ˆæ¡ˆé…ç½®ï¼š** `pyproject.toml`
- **Docker é…ç½®ï¼š** `docker-compose.yml`
- **å»ºç½®è…³æœ¬ï¼š** `Makefile`

### æ ¸å¿ƒç¨‹å¼ç¢¼

- **è³‡æ–™åº«ï¼š** `open_notebook/database/repository.py`, `open_notebook/database/async_migrate.py`
- **æ¨¡å‹ç®¡ç†ï¼š** `open_notebook/domain/models.py`
- **å·¥ä½œæµï¼š** `open_notebook/graphs/chat.py`, `source.py`, `transformation.py`
- **API ä¸»ç¨‹å¼ï¼š** `api/main.py`
- **UI ä¸»ç¨‹å¼ï¼š** `app_home.py`

### å•Ÿå‹•è…³æœ¬

- **Makefileï¼š** `make start-all`, `make stop-all`, `make status`
- **Shell è…³æœ¬ï¼š** `start_system.sh` (åŸç‰ˆ), `start_system_improved.sh` (æ”¹é€²ç‰ˆ)
- **Python è…³æœ¬ï¼š** `run_api.py`

### æ—¥èªŒä½ç½®

- **APIï¼š** `logs/api.log`
- **Workerï¼š** `logs/worker.log` (å¦‚æœä½¿ç”¨æ”¹é€²ç‰ˆè…³æœ¬)
- **Streamlitï¼š** `logs/streamlit.log`
- **SurrealDBï¼š** `docker logs <container_id>`

---

## çµè«–

ä»Šæ—¥é‡åˆ°çš„æ‰€æœ‰å•é¡Œå‡æºæ–¼**ç’°å¢ƒé…ç½®èˆ‡å•Ÿå‹•æ¨¡å¼ä¸ä¸€è‡´**ã€‚æ ¸å¿ƒè§£æ±ºæ–¹æ¡ˆç‚ºï¼š

1. **ä¿®æ­£ .env æª”æ¡ˆï¼š** å°‡ `SURREAL_URL` å¾ `ws://surrealdb/rpc:8000` æ”¹ç‚º `ws://localhost/rpc:8000`
2. **è¨­å®šé è¨­æ¨¡å‹ï¼š** é€é UI æˆ– API è¨­å®š Chat, Transformation, Embedding æ¨¡å‹
3. **ä½¿ç”¨æ­£ç¢ºå•Ÿå‹•æ–¹å¼ï¼š** `make start-all` (åŒ…å« Worker) æˆ–æ”¹é€²ç‰ˆ `start_system.sh`

åŸ·è¡Œé€™äº›ä¿®å¾©å¾Œï¼Œç³»çµ±æ‡‰å¯å®Œå…¨æ­£å¸¸é‹ä½œã€‚

---

---

## å•é¡Œ 5ï¼šstart_system_improved.sh æ˜¯å¦éœ€è¦åŠ å…¥ `ollama serve`

### å•é¡Œæè¿°

ä½¿ç”¨è€…è©¢å•ï¼šã€Œshould I need add 'ollama serve' in start_system_improved.shã€

åœ¨æ”¹é€² start_system.sh è…³æœ¬æ™‚ï¼Œè€ƒæ…®æ˜¯å¦éœ€è¦åœ¨è…³æœ¬ä¸­åŠ å…¥ Ollama çš„å•Ÿå‹•é‚è¼¯ã€‚

### ç³»çµ±ç‹€æ³æª¢æŸ¥

#### ç•¶å‰ Ollama ç‹€æ…‹

```bash
# Ollama å®‰è£ä½ç½®
/usr/local/bin/ollama

# æœå‹™ç‹€æ…‹
â— ollama.service - Ollama Service
     Active: active (running) since Mon 2025-10-20 11:16:07 CST
   Main PID: 2150
     Memory: 12.9G
     Status: enabled (é–‹æ©Ÿè‡ªå‹•å•Ÿå‹•)

# API å¯ç”¨æ€§æ¸¬è©¦
curl http://localhost:11434/api/tags
# âœ… æˆåŠŸè¿”å› 8 å€‹å·²å®‰è£çš„æ¨¡å‹
```

#### å·²å®‰è£çš„æ¨¡å‹

1. `mahonzhan/all-MiniLM-L6-v2` (åµŒå…¥æ¨¡å‹)
2. `zephyr:7b`
3. `gpt-oss:20b`
4. `phi4-mini:3.8b`
5. `codellama:7b`
6. `deepseek-coder-v2:16b`
7. `deepseek-r1:latest` (æ¨ç†æ¨¡å‹)
8. `deepseek-r1:7b`

### åˆ†æçµè«–

**âœ… ä¸éœ€è¦åœ¨ start_system_improved.sh ä¸­åŠ å…¥ `ollama serve`**

#### é—œéµåŸå› 

1. **Ollama å·²ä½œç‚º systemd æœå‹™é‹è¡Œ**
   - é…ç½®ç‚ºç³»çµ±ç´šæœå‹™ (`ollama.service`)
   - é–‹æ©Ÿè‡ªå‹•å•Ÿå‹• (`enabled`)
   - ç”± systemd ç®¡ç†ï¼Œæ¯”è…³æœ¬ç®¡ç†æ›´å¯é 
   - ç•¶å‰ç‹€æ…‹å¥åº·ï¼ˆé‹è¡Œä¸­ï¼ŒAPI æ­£å¸¸å›æ‡‰ï¼‰

2. **é¿å…æœå‹™è¡çª**
   - åœ¨è…³æœ¬ä¸­åŸ·è¡Œ `ollama serve` æœƒèˆ‡ç¾æœ‰ systemd æœå‹™è¡çª
   - é€ æˆåŸ è™Ÿä½”ç”¨ï¼ˆport 11434ï¼‰
   - é€²ç¨‹ç®¡ç†æ··äº‚

3. **åˆ†é›¢é—œæ³¨é»åŸå‰‡**
   - Ollama æ˜¯åŸºç¤è¨­æ–½å±¤ï¼ˆInfrastructureï¼‰
   - Open Notebook æ˜¯æ‡‰ç”¨å±¤ï¼ˆApplicationï¼‰
   - åŸºç¤è¨­æ–½æ‡‰ç”±ç³»çµ±ç®¡ç†ï¼Œä¸æ‡‰ç”±æ‡‰ç”¨è…³æœ¬æ§åˆ¶

4. **Ollama æ˜¯å¯é¸ä¾è³´**
   - Open Notebook æ”¯æ´ 16+ AI æä¾›å•†
   - Ollama åªæ˜¯æœ¬æ©Ÿ AI çš„é¸é …ä¹‹ä¸€
   - ä½¿ç”¨è€…å¯èƒ½é¸æ“‡ä½¿ç”¨é›²ç«¯æœå‹™ï¼ˆOpenAIã€Anthropic ç­‰ï¼‰

### Ollama éƒ¨ç½²æ¨¡å¼å°æ¯”

| éƒ¨ç½²æ¨¡å¼ | å•Ÿå‹•æ–¹å¼ | è‡ªå‹•å•Ÿå‹• | ç®¡ç†æ–¹å¼ | æ˜¯å¦é©ç”¨ |
|---------|---------|---------|---------|---------|
| **systemd æœå‹™** | `systemctl start ollama` | âœ… é–‹æ©Ÿè‡ªå‹•å•Ÿå‹• | systemd ç®¡ç† | **âœ… ç•¶å‰æ¨¡å¼** |
| æ‰‹å‹•å•Ÿå‹• | `ollama serve` | âŒ éœ€æ‰‹å‹•å•Ÿå‹• | è…³æœ¬/çµ‚ç«¯ | âŒ |
| Docker å®¹å™¨ | `docker run ollama/ollama` | ä¾é…ç½®æ±ºå®š | Docker ç®¡ç† | âŒ |

### å»ºè­°çš„å¯¦ä½œæ–¹å¼

#### âœ… é¸é … Aï¼šåŠ å…¥å¥åº·æª¢æŸ¥ï¼ˆæ¨è–¦ï¼‰

åœ¨è…³æœ¬ä¸­æª¢æŸ¥ Ollama å¯ç”¨æ€§ï¼Œä½†**ä¸å•Ÿå‹•**å®ƒï¼š

```bash
#!/bin/bash
# start_system_improved.sh

# Ollama health check (non-blocking)
check_ollama() {
    echo ""
    echo "ğŸ¤– Checking Ollama (optional local AI)..."

    # Check if Ollama service is running
    if systemctl is-active --quiet ollama 2>/dev/null; then
        OLLAMA_URL="${OLLAMA_API_BASE:-http://localhost:11434}"
        if curl -s -m 2 "${OLLAMA_URL}/api/tags" > /dev/null 2>&1; then
            MODEL_COUNT=$(curl -s "${OLLAMA_URL}/api/tags" | grep -o '"name"' | wc -l)
            echo "âœ… Ollama running with ${MODEL_COUNT} models available"
            return 0
        else
            echo "âš ï¸  Ollama service running but API not accessible"
            echo "   Expected at: ${OLLAMA_URL}"
            return 1
        fi
    elif command -v ollama &> /dev/null; then
        echo "â„¹ï¸  Ollama installed but service not running"
        echo "   Start with: sudo systemctl start ollama"
        return 1
    else
        echo "â„¹ï¸  Ollama not installed (using cloud AI providers)"
        return 1
    fi
}

# Run check (doesn't block startup if Ollama is unavailable)
check_ollama || true
```

**å„ªé»ï¼š**
- âœ… ä¸å¹²æ“¾ç¾æœ‰ systemd æœå‹™
- âœ… æä¾›æ¸…æ™°çš„ç‹€æ…‹è³‡è¨Š
- âœ… å¹«åŠ©è¨ºæ–·é…ç½®å•é¡Œ
- âœ… å•Ÿå‹•å¤±æ•—ä¸æœƒé˜»æ–·ç³»çµ±
- âœ… æ”¯æ´åªä½¿ç”¨é›²ç«¯ AI çš„æƒ…å¢ƒ

#### é¸é … Bï¼šç’°å¢ƒè®Šæ•¸æª¢æŸ¥èˆ‡æç¤º

```bash
# Ollama configuration hint
if [ -n "$OLLAMA_API_BASE" ]; then
    echo "ğŸ“ Ollama API configured: $OLLAMA_API_BASE"
elif command -v ollama &> /dev/null && systemctl is-active --quiet ollama; then
    echo "ğŸ’¡ Ollama detected but not configured in .env"
    echo "   To use local AI, add: OLLAMA_API_BASE=http://localhost:11434"
fi
```

#### é¸é … Cï¼šå®Œå…¨ä¸è™•ç†ï¼ˆæœ€ç°¡å–®ï¼‰

å› ç‚º Ollama æ˜¯å¯é¸ä¾è³´ï¼Œä¸”å·²æœ‰ç³»çµ±ç´šç®¡ç†ï¼Œå¯ä»¥å®Œå…¨ä¸åœ¨è…³æœ¬ä¸­è™•ç†ã€‚

### ä½•æ™‚æ‰éœ€è¦åœ¨è…³æœ¬ä¸­å•Ÿå‹• Ollamaï¼Ÿ

åªæœ‰åœ¨ä»¥ä¸‹ç‰¹æ®Šæƒ…æ³ä¸‹æ‰æ‡‰è©²åœ¨è…³æœ¬ä¸­å•Ÿå‹• Ollamaï¼š

#### æƒ…å¢ƒ 1ï¼šé systemd ç’°å¢ƒ

```bash
# æª¢æŸ¥æ˜¯å¦ç‚º systemd æœå‹™
if ! systemctl status ollama &>/dev/null; then
    # ä¸æ˜¯ systemd æœå‹™ï¼Œæ‰‹å‹•å•Ÿå‹•
    if command -v ollama &>/dev/null; then
        echo "Starting Ollama manually..."
        OLLAMA_HOST=0.0.0.0:11434 ollama serve > logs/ollama.log 2>&1 &
        OLLAMA_PID=$!
        echo $OLLAMA_PID > .ollama.pid
    fi
fi
```

#### æƒ…å¢ƒ 2ï¼šDocker Compose æ•´åˆ

```yaml
# docker-compose.yml
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
```

```bash
# start_system_improved.sh
docker compose up -d ollama
```

#### æƒ…å¢ƒ 3ï¼šè‡ªè¨‚é…ç½®éœ€æ±‚

ç•¶éœ€è¦ç‰¹å®šçš„ Ollama é…ç½®ï¼ˆèˆ‡ç³»çµ±æœå‹™ä¸åŒï¼‰ï¼š

```bash
# ä½¿ç”¨è‡ªè¨‚åŸ è™Ÿæˆ–é…ç½®
OLLAMA_HOST=0.0.0.0:8080 \
OLLAMA_KEEP_ALIVE=10m \
OLLAMA_MAX_LOADED_MODELS=3 \
ollama serve &
```

**ä½ çš„æƒ…æ³ï¼š** âŒ ä»¥ä¸Šæƒ…å¢ƒéƒ½ä¸é©ç”¨

### ç›¸é—œç’°å¢ƒè®Šæ•¸é…ç½®

#### Open Notebook ä¸­çš„ Ollama é…ç½®

**æª”æ¡ˆï¼š** `.env`

```bash
# Ollama é…ç½®ï¼ˆå¯é¸ï¼‰
OLLAMA_API_BASE="http://localhost:11434"  # æœ¬æ©Ÿæ¨¡å¼

# æˆ–é‡å°ä¸åŒéƒ¨ç½²æƒ…å¢ƒï¼š
# OLLAMA_API_BASE="http://host.docker.internal:11434"  # Docker æ¨¡å¼
# OLLAMA_API_BASE="http://192.168.1.100:11434"         # é ç«¯ä¼ºæœå™¨
```

#### Ollama æœå‹™é…ç½®

**æª”æ¡ˆï¼š** `/etc/systemd/system/ollama.service`

```ini
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
Type=simple
ExecStart=/usr/local/bin/ollama serve
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_KEEP_ALIVE=5m"
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
```

**é—œéµç’°å¢ƒè®Šæ•¸èªªæ˜ï¼š**

| è®Šæ•¸ | ç”¨é€” | é è¨­å€¼ | å»ºè­°å€¼ |
|------|------|--------|--------|
| `OLLAMA_HOST` | ç¶å®šä½å€å’ŒåŸ è™Ÿ | `127.0.0.1:11434` | `0.0.0.0:11434` (å…è¨±å¤–éƒ¨é€£ç·š) |
| `OLLAMA_KEEP_ALIVE` | æ¨¡å‹åœ¨è¨˜æ†¶é«”ä¸­ä¿ç•™æ™‚é–“ | `5m` | `5m` - `30m` |
| `OLLAMA_MAX_LOADED_MODELS` | åŒæ™‚è¼‰å…¥æ¨¡å‹æ•¸é‡ | `1` | `2-3` (å–æ±ºæ–¼è¨˜æ†¶é«”) |

### ç¶²è·¯é…ç½®è€ƒé‡

#### æœ¬æ©Ÿå•Ÿå‹•æ¨¡å¼çš„ Ollama é…ç½®

**ç•¶å‰æƒ…å¢ƒï¼š** Open Notebook åœ¨æœ¬æ©ŸåŸ·è¡Œï¼ˆé€é `make start-all`ï¼‰

```bash
# .env é…ç½®
OLLAMA_API_BASE="http://localhost:11434"

# Ollama æœå‹™é…ç½®
OLLAMA_HOST=0.0.0.0:11434  # å…è¨±æœ¬æ©Ÿå„ç¨®ä¾†æºé€£ç·š
```

**ç‚ºä»€éº¼éœ€è¦ `0.0.0.0:11434`ï¼Ÿ**
- é›–ç„¶ Open Notebook åœ¨æœ¬æ©Ÿï¼Œä½†é€é uv è™›æ“¬ç’°å¢ƒåŸ·è¡Œ
- æŸäº›æƒ…æ³ä¸‹ `127.0.0.1` å’Œ `localhost` çš„è§£æå¯èƒ½ä¸åŒ
- `0.0.0.0` ç¢ºä¿æ‰€æœ‰æœ¬æ©Ÿé€£ç·šéƒ½èƒ½é€š

### æœ€ä½³å¯¦å‹™å»ºè­°

#### 1. ç³»çµ±æœå‹™ç®¡ç†

```bash
# å•Ÿå‹• Ollama
sudo systemctl start ollama

# åœæ­¢ Ollama
sudo systemctl stop ollama

# é‡å•Ÿ Ollama
sudo systemctl restart ollama

# æŸ¥çœ‹ç‹€æ…‹
sudo systemctl status ollama

# æŸ¥çœ‹æ—¥èªŒ
sudo journalctl -u ollama -f
```

#### 2. å¥åº·æª¢æŸ¥è…³æœ¬

å»ºç«‹ç¨ç«‹çš„å¥åº·æª¢æŸ¥è…³æœ¬ï¼š

```bash
#!/bin/bash
# scripts/check-ollama.sh

OLLAMA_API_BASE=${OLLAMA_API_BASE:-"http://localhost:11434"}

echo "Checking Ollama health at ${OLLAMA_API_BASE}..."

if curl -s -m 5 "${OLLAMA_API_BASE}/api/tags" > /dev/null; then
    echo "âœ… Ollama is accessible"
    echo ""
    echo "Available models:"
    curl -s "${OLLAMA_API_BASE}/api/tags" | \
        grep -o '"name":"[^"]*"' | \
        cut -d'"' -f4
    exit 0
else
    echo "âŒ Ollama is not accessible"
    echo ""
    echo "Troubleshooting steps:"
    echo "1. Check if service is running: systemctl status ollama"
    echo "2. Verify API base: echo \$OLLAMA_API_BASE"
    echo "3. Test manually: curl ${OLLAMA_API_BASE}/api/tags"
    exit 1
fi
```

#### 3. start_system_improved.sh æ•´åˆ

```bash
#!/bin/bash
# start_system_improved.sh - å®Œæ•´ç‰ˆæœ¬

set -e
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$PROJECT_DIR"

echo "ğŸš€ Starting Open Notebook System..."

# Create necessary directories
mkdir -p logs

# Check and fix .env for local mode
if [ ! -f ".env" ]; then
    echo "âš ï¸  .env not found, copying from template..."
    cp setup_guide/docker.env .env
fi

if grep -q "ws://surrealdb" .env; then
    echo "âš ï¸  Fixing SURREAL_URL for local mode..."
    sed -i.bak 's|ws://surrealdb/rpc:8000|ws://localhost/rpc:8000|g' .env
    echo "âœ… Updated SURREAL_URL"
fi

# Source .env file
set -a
source .env
set +a

# Function to check port
check_port() {
    lsof -Pi :$1 -sTCP:LISTEN -t >/dev/null 2>&1
}

# Optional: Check Ollama (non-blocking)
check_ollama() {
    echo ""
    echo "ğŸ¤– Checking Ollama (optional local AI)..."

    if systemctl is-active --quiet ollama 2>/dev/null; then
        OLLAMA_URL="${OLLAMA_API_BASE:-http://localhost:11434}"
        if curl -s -m 2 "${OLLAMA_URL}/api/tags" > /dev/null 2>&1; then
            MODEL_COUNT=$(curl -s "${OLLAMA_URL}/api/tags" | grep -o '"name"' | wc -l)
            echo "âœ… Ollama running with ${MODEL_COUNT} models"
        else
            echo "âš ï¸  Ollama service active but API not responding"
        fi
    elif command -v ollama &> /dev/null; then
        echo "â„¹ï¸  Ollama installed but not running"
        echo "   Start: sudo systemctl start ollama"
    else
        echo "â„¹ï¸  Ollama not installed (optional)"
    fi
}

check_ollama || true

# Start SurrealDB
echo ""
echo "ğŸ“Š Starting SurrealDB..."
if check_port 8000; then
    echo "âœ… SurrealDB already running"
else
    docker compose up -d surrealdb
    sleep 5
    echo "âœ… SurrealDB started"
fi

# Start API
echo ""
echo "ğŸ”§ Starting API Backend..."
if check_port 5055; then
    echo "âš ï¸  Port 5055 in use, skipping"
else
    uv run --env-file .env uvicorn api.main:app --host 0.0.0.0 --port 5055 > logs/api.log 2>&1 &
    echo $! > .api.pid
    echo "âœ… API started (PID: $(cat .api.pid))"
    sleep 3
fi

# Start Worker
echo ""
echo "âš™ï¸  Starting Background Worker..."
if pgrep -f "surreal-commands-worker" > /dev/null; then
    echo "âœ… Worker already running"
else
    uv run --env-file .env surreal-commands-worker --import-modules commands > logs/worker.log 2>&1 &
    echo $! > .worker.pid
    echo "âœ… Worker started (PID: $(cat .worker.pid))"
    sleep 2
fi

# Start Streamlit
echo ""
echo "ğŸ¨ Starting Streamlit UI..."
if check_port 8502; then
    echo "âš ï¸  Port 8502 in use, skipping"
else
    uv run --env-file .env streamlit run app_home.py > logs/streamlit.log 2>&1 &
    echo $! > .streamlit.pid
    echo "âœ… Streamlit started (PID: $(cat .streamlit.pid))"
fi

echo ""
echo "âœ¨ All services started!"
echo ""
echo "ğŸ“ Access Points:"
echo "   - UI:        http://localhost:8502"
echo "   - API:       http://localhost:5055"
echo "   - API Docs:  http://localhost:5055/docs"
if systemctl is-active --quiet ollama 2>/dev/null; then
    echo "   - Ollama:    http://localhost:11434"
fi
echo ""
echo "ğŸ“ Logs:"
echo "   - API:       tail -f logs/api.log"
echo "   - Worker:    tail -f logs/worker.log"
echo "   - Streamlit: tail -f logs/streamlit.log"
echo ""
echo "ğŸ›‘ Stop: ./stop_system.sh"
```

### Ollama ç–‘é›£æ’è§£

#### å•é¡Œ 1ï¼šOpen Notebook ç„¡æ³•é€£æ¥ Ollama

**ç—‡ç‹€ï¼š** UI ä¸­é¡¯ç¤ºã€ŒOllama unavailableã€

**è¨ºæ–·æ­¥é©Ÿï¼š**

```bash
# 1. æª¢æŸ¥æœå‹™ç‹€æ…‹
systemctl status ollama

# 2. æ¸¬è©¦ API
curl http://localhost:11434/api/tags

# 3. æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
echo $OLLAMA_API_BASE

# 4. æª¢æŸ¥é˜²ç«ç‰†
sudo ufw status | grep 11434
```

**å¸¸è¦‹åŸå› èˆ‡è§£æ±ºæ–¹æ¡ˆï¼š**

| åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
|------|---------|
| æœå‹™æœªé‹è¡Œ | `sudo systemctl start ollama` |
| ç¶å®šä½å€éŒ¯èª¤ | ç¢ºä¿ `OLLAMA_HOST=0.0.0.0:11434` |
| ç’°å¢ƒè®Šæ•¸æœªè¨­å®š | åœ¨ `.env` ä¸­åŠ å…¥ `OLLAMA_API_BASE` |
| é˜²ç«ç‰†é˜»æ“‹ | `sudo ufw allow 11434` |

#### å•é¡Œ 2ï¼šOllama è¨˜æ†¶é«”ä½¿ç”¨éé«˜

**ç•¶å‰ç‹€æ…‹ï¼š** Memory: 12.9G

**å„ªåŒ–å»ºè­°ï¼š**

```bash
# 1. é™åˆ¶åŒæ™‚è¼‰å…¥çš„æ¨¡å‹æ•¸é‡
echo 'OLLAMA_MAX_LOADED_MODELS=2' | sudo tee -a /etc/systemd/system/ollama.service.d/override.conf

# 2. æ¸›å°‘æ¨¡å‹åœ¨è¨˜æ†¶é«”ä¸­çš„ä¿ç•™æ™‚é–“
echo 'OLLAMA_KEEP_ALIVE=3m' | sudo tee -a /etc/systemd/system/ollama.service.d/override.conf

# 3. é‡æ–°è¼‰å…¥é…ç½®
sudo systemctl daemon-reload
sudo systemctl restart ollama

# 4. ç§»é™¤ä¸å¸¸ç”¨çš„å¤§å‹æ¨¡å‹
ollama rm gpt-oss:20b  # 13.7GB
ollama rm deepseek-coder-v2:16b  # 8.9GB
```

### æ–‡ä»¶åƒè€ƒ

- **Ollama å®Œæ•´æŒ‡å—ï¼š** [docs/features/ollama.md](docs/features/ollama.md)
- **AI æ¨¡å‹é…ç½®ï¼š** [docs/features/ai-models.md](docs/features/ai-models.md)
- **ç–‘é›£æ’è§£ FAQï¼š** [docs/troubleshooting/faq.md](docs/troubleshooting/faq.md)

### ç¸½çµ

#### æ ¸å¿ƒçµè«–

**âŒ ä¸éœ€è¦åœ¨ start_system_improved.sh ä¸­åŠ å…¥ `ollama serve`**

#### åŸå› 

1. âœ… Ollama å·²ä½œç‚º systemd æœå‹™é‹è¡Œ
2. âœ… é–‹æ©Ÿè‡ªå‹•å•Ÿå‹•ï¼Œç³»çµ±ç´šç®¡ç†
3. âœ… ç•¶å‰ç‹€æ…‹å¥åº·ï¼ŒAPI æ­£å¸¸é‹ä½œ
4. âœ… é¿å…èˆ‡ç¾æœ‰æœå‹™è¡çª

#### å»ºè­°åšæ³•

1. âœ… åŠ å…¥å¥åº·æª¢æŸ¥ï¼ˆå¯é¸ï¼Œä¸é˜»æ–·å•Ÿå‹•ï¼‰
2. âœ… æä¾›æ¸…æ™°çš„ç‹€æ…‹è³‡è¨Š
3. âœ… è®“ systemd ç®¡ç† Ollama æœå‹™
4. âœ… è…³æœ¬å°ˆæ³¨æ–¼ Open Notebook æœ¬èº«çš„å•Ÿå‹•

#### é©ç”¨åŸå‰‡

> **åŸºç¤è¨­æ–½ç”±ç³»çµ±ç®¡ç†ï¼Œæ‡‰ç”¨ç¨‹å¼ç”±è…³æœ¬ç®¡ç†**
>
> Ollama å±¬æ–¼åŸºç¤è¨­æ–½å±¤ï¼Œæ‡‰è©²é€é systemd ç­‰ç³»çµ±ç´šå·¥å…·ç®¡ç†ï¼Œè€Œä¸æ˜¯è¢«æ‡‰ç”¨å±¤è…³æœ¬æ§åˆ¶ã€‚

---

## å•é¡Œ 6ï¼š.env æª”æ¡ˆæå£ - è…³æœ¬ä»£ç¢¼æ··å…¥

### å•é¡Œæè¿°

ä½¿ç”¨è€…åŸ·è¡Œ `start_system_improved.sh` æ™‚é‡åˆ°éŒ¯èª¤ï¼š

```bash
failed to read /home/mapleleaf/LCJRepos/projects/lcj_open_notebook/.env:
line 13: key cannot contain a space
```

### éŒ¯èª¤ç™¼ç”Ÿä½ç½®

**è…³æœ¬ä½ç½®ï¼š** [start_system_improved.sh:18-20](start_system_improved.sh#L18-L20)

```bash
# Source .env file
set -a
source .env  # â† Error occurs here
set +a
```

### æ ¹æœ¬åŸå› 

**è¨ºæ–·çµæœï¼š** `.env` æª”æ¡ˆè¢«æ„å¤–æ¤å…¥å¤§é‡ bash è…³æœ¬ä»£ç¢¼

#### æå£å…§å®¹åˆ†æ

**Line 13:**
```bash
mkdir -p logs
```
- âŒ é€™æ˜¯ bash å‘½ä»¤ï¼Œä¸æ˜¯ç’°å¢ƒè®Šæ•¸
- âŒ é•åç’°å¢ƒè®Šæ•¸èªæ³•è¦å‰‡ï¼ˆkey ä¸èƒ½æœ‰ç©ºæ ¼ï¼‰

**Lines 18-24:**
```bash
# åœ¨ç¬¬ 20 è¡Œå¾ŒåŠ å…¥
# Check and fix SURREAL_URL for local mode
if grep -q "ws://surrealdb" .env; then
    echo "âš ï¸  Detected Docker network URL, fixing for local mode..."
    sed -i.bak 's|ws://localhost/rpc:8000|ws://localhost/rpc:8000|g' .env
    echo "âœ… Updated SURREAL_URL to ws://localhost/rpc:8000"
fi
```
- âŒ å®Œæ•´çš„ bash if èªå¥å’Œ sed å‘½ä»¤
- âŒ æ‡‰è©²åœ¨å•Ÿå‹•è…³æœ¬ä¸­ï¼Œä¸æ˜¯ç’°å¢ƒè®Šæ•¸æ–‡ä»¶

**Lines 67-79:**
```bash
# Start Background Worker
echo ""
echo "âš™ï¸  Starting Background Worker..."
if pgrep -f "surreal-commands-worker" > /dev/null; then
    echo "âœ… Worker already running"
else
    echo "Starting worker in background..."
    uv run --env-file .env surreal-commands-worker --import-modules commands > logs/worker.log 2>&1 &
    WORKER_PID=$!
    echo $WORKER_PID > .worker.pid
    echo "âœ… Worker started (PID: $WORKER_PID, logs: logs/worker.log)"
    sleep 2
fi
```
- âŒ Worker å•Ÿå‹•è…³æœ¬çš„å®Œæ•´é‚è¼¯
- âŒ åš´é‡æ±¡æŸ“ç’°å¢ƒè®Šæ•¸æ–‡ä»¶

### ç‚ºä»€éº¼æœƒå¤±æ•—

#### Bash ç’°å¢ƒè®Šæ•¸èªæ³•è¦å‰‡

```bash
# âœ… æ­£ç¢ºæ ¼å¼
KEY=value
KEY="value with spaces"
KEY='single quoted'

# âŒ éŒ¯èª¤æ ¼å¼
mkdir -p logs           # é€™æ˜¯å‘½ä»¤ï¼Œä¸æ˜¯è®Šæ•¸
if [ test ]; then       # æ§åˆ¶çµæ§‹ä¸å…è¨±
echo "message"          # å‡½æ•¸èª¿ç”¨ä¸å…è¨±
```

#### `source` å‘½ä»¤è¡Œç‚º

ç•¶ bash åŸ·è¡Œ `source .env` æ™‚ï¼š
1. é€è¡Œè®€å–æ–‡ä»¶
2. å˜—è©¦å°‡æ¯è¡Œä½œç‚º bash èªå¥åŸ·è¡Œ
3. å°æ–¼è®Šæ•¸è³¦å€¼ï¼š`KEY=value` â†’ è¨­å®šç’°å¢ƒè®Šæ•¸
4. å°æ–¼å…¶ä»–èªå¥ï¼šå˜—è©¦åŸ·è¡Œç‚ºå‘½ä»¤
5. é‡åˆ°éæ³•èªæ³• â†’ **ç«‹å³å¤±æ•—ä¸¦å ±éŒ¯**

**Line 13 è§£æï¼š**
```bash
mkdir -p logs
```
- Bash å°‡ `mkdir` è­˜åˆ¥ç‚ºå‘½ä»¤
- `-p` å’Œ `logs` è­˜åˆ¥ç‚ºåƒæ•¸
- ä½†åœ¨è®Šæ•¸è³¦å€¼ä¸Šä¸‹æ–‡ä¸­ï¼Œé€™é•åäº†èªæ³•è¦å‰‡
- å ±éŒ¯ï¼šã€Œkey cannot contain a spaceã€ï¼ˆå› ç‚º bash æœŸå¾… `KEY=VALUE` æ ¼å¼ï¼‰

### è§£æ±ºæ–¹æ¡ˆ

#### å¯¦æ–½æ­¥é©Ÿ

**1. å‚™ä»½æå£çš„æ–‡ä»¶ï¼ˆå·²å®Œæˆï¼‰**
```bash
# è‡ªå‹•å‚™ä»½ç”±ç·¨è¼¯å™¨ç”¢ç”Ÿ
.env.bak  # åŒ…å«åŸå§‹æå£å…§å®¹
```

**2. é‡å¯«ä¹¾æ·¨çš„ .env æ–‡ä»¶ï¼ˆå·²å®Œæˆï¼‰**

æ¸…ç†å¾Œçš„æ­£ç¢ºæ ¼å¼ï¼š

```bash
# .env

# SECURITY
OPEN_NOTEBOOK_PASSWORD="mapleleaf123456"

# OPENAI
# OPENAI_API_KEY=

# ANTHROPIC
# ANTHROPIC_API_KEY=

# GEMINI
# GOOGLE_API_KEY=

# OLLAMA
# OLLAMA_API_BASE="http://10.20.30.20:11434"

# ... (å…¶ä»– AI æä¾›å•†é…ç½®)

# CONNECTION DETAILS FOR YOUR SURREAL DB
SURREAL_URL="ws://localhost/rpc:8000"
SURREAL_USER="root"
SURREAL_PASSWORD="root"
SURREAL_NAMESPACE="open_notebook"
SURREAL_DATABASE="staging"

# FIRECRAWL
FIRECRAWL_API_KEY=

# JINA
JINA_API_KEY=
```

**ç‰¹é»ï¼š**
- âœ… åªåŒ…å« `KEY=value` æ ¼å¼çš„ç’°å¢ƒè®Šæ•¸
- âœ… è¨»è§£ä½¿ç”¨ `#` é–‹é ­
- âœ… æ²’æœ‰ä»»ä½• bash è…³æœ¬é‚è¼¯
- âœ… ä¿ç•™æ‰€æœ‰åŸå§‹é…ç½®å€¼ï¼ˆå¦‚ OPEN_NOTEBOOK_PASSWORDï¼‰
- âœ… ç§»é™¤æ‰€æœ‰åµŒå…¥çš„è…³æœ¬ä»£ç¢¼

**3. é©—è­‰æ–‡ä»¶èªæ³•ï¼ˆå»ºè­°åŸ·è¡Œï¼‰**

```bash
# æ¸¬è©¦ .env æ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£ç¢ºè¼‰å…¥
set -a
source .env
set +a
echo "âœ… .env file is valid"
```

### é é˜²æªæ–½

#### .env æ–‡ä»¶æœ€ä½³å¯¦è¸

**âœ… å…è¨±çš„å…§å®¹ï¼š**
```bash
# 1. è¨»è§£
# This is a comment

# 2. ç’°å¢ƒè®Šæ•¸è³¦å€¼
KEY=value
KEY="value with spaces"
KEY='single quoted'

# 3. ç©ºè¡Œ
```

**âŒ ç¦æ­¢çš„å…§å®¹ï¼š**
```bash
# 1. Bash å‘½ä»¤
mkdir -p logs

# 2. æ§åˆ¶çµæ§‹
if [ test ]; then
    command
fi

# 3. å‡½æ•¸èª¿ç”¨
echo "message"

# 4. ç®¡é“å’Œé‡å®šå‘
command > file

# 5. è®Šæ•¸å±•é–‹ï¼ˆåœ¨è³¦å€¼ä¸­å¯ä»¥ï¼Œä½†å®¹æ˜“å‡ºéŒ¯ï¼‰
KEY=${OTHER_KEY}/path  # å¯èƒ½å°è‡´å•é¡Œ
```

#### è…³æœ¬èˆ‡é…ç½®åˆ†é›¢

**åŸå‰‡ï¼š**
> **é…ç½®æ–‡ä»¶åªåŒ…å«æ•¸æ“šï¼Œé‚è¼¯ä»£ç¢¼æ”¾åœ¨è…³æœ¬ä¸­**

**æ­£ç¢ºçš„æ¶æ§‹ï¼š**

```bash
# .env - åªæœ‰é…ç½®æ•¸æ“š
SURREAL_URL="ws://localhost/rpc:8000"
LOG_DIR="logs"

# start_system.sh - åŒ…å«é‚è¼¯
#!/bin/bash
source .env

# æ ¹æ“šé…ç½®åŸ·è¡Œé‚è¼¯
mkdir -p "$LOG_DIR"

if [[ "$SURREAL_URL" == *"surrealdb"* ]]; then
    echo "Detected Docker mode"
    # Fix configuration
fi
```

### æŠ€è¡“ç´°ç¯€

#### ç‚ºä»€éº¼æœƒç™¼ç”Ÿæ··å…¥

**å¯èƒ½åŸå› ï¼š**

1. **è¤‡è£½è²¼ä¸ŠéŒ¯èª¤ï¼š** å¾å•Ÿå‹•è…³æœ¬è¤‡è£½ä»£ç¢¼æ™‚èª¤è²¼åˆ° .env
2. **ç·¨è¼¯å™¨èª¤æ“ä½œï¼š** åœ¨éŒ¯èª¤çš„æ–‡ä»¶ä¸­ç·¨è¼¯
3. **è…³æœ¬ç”ŸæˆéŒ¯èª¤ï¼š** æŸå€‹è‡ªå‹•åŒ–è…³æœ¬å°‡ä»£ç¢¼å¯«å…¥éŒ¯èª¤ä½ç½®
4. **åˆä½µè¡çªï¼š** Git åˆä½µæ™‚å°‡è…³æœ¬å…§å®¹èª¤åˆä½µåˆ° .env

#### æª¢æ¸¬æå£çš„æ–¹æ³•

**å¿«é€Ÿæª¢æ¸¬è…³æœ¬ï¼š**
```bash
#!/bin/bash
# check_env_file.sh

echo "ğŸ” Checking .env file syntax..."

# Try to source it
if set -a && source .env 2>/dev/null && set +a; then
    echo "âœ… .env file is valid"
else
    echo "âŒ .env file has syntax errors"
    echo ""
    echo "Common issues to check:"
    echo "  - Lines with spaces in variable names"
    echo "  - Bash commands instead of KEY=VALUE"
    echo "  - Control structures (if/for/while)"
    echo "  - Function calls"
fi

# Check for suspicious patterns
echo ""
echo "ğŸ” Checking for suspicious patterns..."

if grep -E "^(if|for|while|echo|mkdir|cd|cp|mv)" .env; then
    echo "âš ï¸  Found bash commands in .env file"
else
    echo "âœ… No bash commands detected"
fi
```

#### Bash è®Šæ•¸åç¨±è¦å‰‡

**æœ‰æ•ˆçš„è®Šæ•¸åï¼š**
```bash
KEY=value          # âœ… ç°¡å–®å­—æ¯
MY_KEY=value       # âœ… åº•ç·šåˆ†éš”
KEY123=value       # âœ… åŒ…å«æ•¸å­—
_KEY=value         # âœ… é–‹é ­åº•ç·š
```

**ç„¡æ•ˆçš„è®Šæ•¸åï¼š**
```bash
MY KEY=value       # âŒ åŒ…å«ç©ºæ ¼
123KEY=value       # âŒ æ•¸å­—é–‹é ­
MY-KEY=value       # âŒ é€£å­—è™Ÿ
MY.KEY=value       # âŒ é»è™Ÿ
```

### é©—è­‰èˆ‡æ¸¬è©¦

#### æ¸¬è©¦ .env è¼‰å…¥

**å‘½ä»¤ï¼š**
```bash
cd /home/mapleleaf/LCJRepos/projects/lcj_open_notebook

# æ¸¬è©¦è¼‰å…¥
set -a
source .env
set +a

# é©—è­‰é—œéµè®Šæ•¸
echo "SURREAL_URL: $SURREAL_URL"
echo "OPEN_NOTEBOOK_PASSWORD: $OPEN_NOTEBOOK_PASSWORD"

# ç¢ºèªç„¡éŒ¯èª¤
echo "âœ… Environment loaded successfully"
```

**é æœŸè¼¸å‡ºï¼š**
```bash
SURREAL_URL: ws://localhost/rpc:8000
OPEN_NOTEBOOK_PASSWORD: mapleleaf123456
âœ… Environment loaded successfully
```

#### æ¸¬è©¦å•Ÿå‹•è…³æœ¬

**å‘½ä»¤ï¼š**
```bash
./start_system_improved.sh
```

**é æœŸçµæœï¼š**
- âœ… ä¸æ‡‰å†å‡ºç¾ "key cannot contain a space" éŒ¯èª¤
- âœ… ç’°å¢ƒè®Šæ•¸æ­£ç¢ºè¼‰å…¥
- âœ… æ‰€æœ‰æœå‹™é †åˆ©å•Ÿå‹•

### ç›¸é—œæª”æ¡ˆ

**ä¿®æ”¹çš„æª”æ¡ˆï¼š**
- `.env` - å®Œå…¨é‡å¯«ï¼Œç§»é™¤æ‰€æœ‰è…³æœ¬ä»£ç¢¼
- `.env.bak` - è‡ªå‹•å‚™ä»½ï¼ˆåŒ…å«æå£å…§å®¹ï¼‰

**å—å½±éŸ¿çš„è…³æœ¬ï¼š**
- `start_system_improved.sh` - ç¾åœ¨å¯ä»¥æ­£ç¢ºè¼‰å…¥ .env
- `stop_system.sh` - åŒæ¨£ä¾è³´ .env è¼‰å…¥

### ç¶“é©—æ•™è¨“

#### é—œéµåŸå‰‡

1. **é…ç½®èˆ‡ä»£ç¢¼åˆ†é›¢**
   - .env = æ•¸æ“š
   - .sh = é‚è¼¯

2. **åš´æ ¼çš„èªæ³•è¦å‰‡**
   - ç’°å¢ƒè®Šæ•¸æ–‡ä»¶åªèƒ½åŒ…å« `KEY=VALUE` å’Œè¨»è§£
   - ä»»ä½•å…¶ä»–èªæ³•éƒ½æœƒå°è‡´å¤±æ•—

3. **ç‰ˆæœ¬æ§åˆ¶æœ€ä½³å¯¦è¸**
   - .env é€šå¸¸åŠ å…¥ .gitignore
   - æä¾› .env.example ä½œç‚ºæ¨¡æ¿
   - ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶è¿½è¹¤ .env.exampleï¼Œä¸è¿½è¹¤ .env

4. **è‡ªå‹•åŒ–æª¢æŸ¥**
   - åœ¨ CI/CD ä¸­åŠ å…¥ .env èªæ³•æª¢æŸ¥
   - ä½¿ç”¨å·¥å…·å¦‚ `dotenv-linter` é€²è¡Œé©—è­‰

### ç¸½çµ

#### æ ¸å¿ƒå•é¡Œ
`.env` æª”æ¡ˆè¢«æ„å¤–æ¤å…¥å¤§é‡ bash è…³æœ¬ä»£ç¢¼ï¼ˆå‘½ä»¤ã€æ§åˆ¶çµæ§‹ã€å‡½æ•¸èª¿ç”¨ï¼‰ï¼Œé•åç’°å¢ƒè®Šæ•¸æ–‡ä»¶çš„èªæ³•è¦å‰‡ã€‚

#### è§£æ±ºæ–¹æ¡ˆ
å®Œå…¨é‡å¯« `.env` æ–‡ä»¶ï¼Œåªä¿ç•™ç´”ç²¹çš„ `KEY=VALUE` ç’°å¢ƒè®Šæ•¸å®šç¾©ã€‚

#### çµæœ
âœ… `.env` æ–‡ä»¶ç¾åœ¨å¯ä»¥æ­£ç¢ºè¢« `source` å‘½ä»¤è¼‰å…¥
âœ… æ‰€æœ‰åŸå§‹é…ç½®å€¼éƒ½å·²ä¿ç•™
âœ… ç§»é™¤æ‰€æœ‰åµŒå…¥çš„è…³æœ¬é‚è¼¯
âœ… `start_system_improved.sh` ç¾åœ¨å¯ä»¥æ­£å¸¸åŸ·è¡Œ

#### æ ¹æœ¬åŸå› 
é…ç½®èˆ‡ä»£ç¢¼çš„æ··æ·† - å°‡æ‡‰è©²åœ¨å•Ÿå‹•è…³æœ¬ä¸­çš„é‚è¼¯éŒ¯èª¤æ”¾å…¥ç’°å¢ƒè®Šæ•¸æ–‡ä»¶ã€‚

#### é é˜²æªæ–½
- åš´æ ¼éµå®ˆ .env æ–‡ä»¶æ ¼å¼è¦ç¯„
- é…ç½®èˆ‡é‚è¼¯åˆ†é›¢
- ä½¿ç”¨è‡ªå‹•åŒ–å·¥å…·æª¢æŸ¥æ–‡ä»¶èªæ³•

---

## å•é¡Œ 7ï¼šèŠå¤©è¨Šæ¯ç™¼é€å¤±æ•—ï¼ˆé‡ç¾ï¼‰ - æ¨¡å‹åç¨±æ‹¼å¯«éŒ¯èª¤

### å•é¡Œæè¿°

ä½¿ç”¨è€…å†æ¬¡é‡åˆ° "Failed to send message" éŒ¯èª¤ï¼Œå³ä½¿åœ¨ä¹‹å‰å·²ç¶“é…ç½®äº†é è¨­æ¨¡å‹ã€‚

### åˆæ­¥è¨ºæ–·

**ç³»çµ±ç‹€æ…‹æª¢æŸ¥ï¼š**
```bash
# âœ… SurrealDB é‹è¡Œä¸­
docker ps | grep surrealdb
# lcj_open_notebook-surrealdb-1 (Up 3 hours)

# âœ… API é‹è¡Œä¸­
pgrep -af "uvicorn api.main:app"
# PID 2607, 2637

# âœ… API å¥åº·
curl http://localhost:5055/health
# {"status":"healthy"}

# âœ… é è¨­æ¨¡å‹å·²é…ç½®
curl -H "Authorization: Bearer mapleleaf123456" http://localhost:5055/api/models/defaults
# Returns default models configuration
```

### æ ¹æœ¬åŸå› åˆ†æ

#### ç™¼ç¾éç¨‹

1. **é è¨­æ¨¡å‹é…ç½®å­˜åœ¨**
```json
{
  "default_chat_model": "model:s0azyiw39ufog3vcte7n",
  "default_transformation_model": "model:s0azyiw39ufog3vcte7n",
  "large_context_model": "model:s0azyiw39ufog3vcte7n",
  "default_embedding_model": "model:pv2kskoqa1gwb8quqnqn"
}
```

2. **æª¢æŸ¥å·²é…ç½®çš„æ¨¡å‹**
```bash
curl -H "Authorization: Bearer mapleleaf123456" http://localhost:5055/api/models
```

**çµæœï¼š**
```json
[
  {
    "id": "model:s0azyiw39ufog3vcte7n",
    "name": "gtp-oss:20b",  // âŒ æ‹¼å¯«éŒ¯èª¤ï¼
    "provider": "ollama",
    "type": "language"
  },
  {
    "id": "model:pv2kskoqa1gwb8quqnqn",
    "name": "all-MiniLM-L6-v2",
    "provider": "ollama",
    "type": "embedding"
  }
]
```

3. **é©—è­‰ Ollama ä¸­çš„å¯¦éš›æ¨¡å‹åç¨±**
```bash
ollama list | grep -E "gpt-oss|gtp-oss"
# gpt-oss:20b    aa4295ac10c3    13 GB     7 weeks ago
```

#### æ ¹æœ¬åŸå› 

**è³‡æ–™åº«ä¸­çš„æ¨¡å‹åç¨±ï¼š** `gtp-oss:20b` ï¼ˆæ‹¼å¯«éŒ¯èª¤ï¼‰
**Ollama ä¸­çš„å¯¦éš›åç¨±ï¼š** `gpt-oss:20b` ï¼ˆæ­£ç¢ºæ‹¼å¯«ï¼‰

ç•¶ç³»çµ±å˜—è©¦ä½¿ç”¨é è¨­èŠå¤©æ¨¡å‹æ™‚ï¼š
1. å¾è³‡æ–™åº«è®€å– `default_chat_model` â†’ `model:s0azyiw39ufog3vcte7n`
2. æŸ¥è©¢æ¨¡å‹è©³ç´°è³‡è¨Š â†’ `name: "gtp-oss:20b"`
3. å‘¼å« Ollama API ä½¿ç”¨ `gtp-oss:20b` æ¨¡å‹
4. **Ollama å›æ‡‰éŒ¯èª¤ï¼šæ¨¡å‹ä¸å­˜åœ¨**
5. èŠå¤©è¨Šæ¯ç™¼é€å¤±æ•—

### éŒ¯èª¤ç™¼ç”Ÿä½ç½®

**è³‡æ–™æµç¨‹è¿½è¹¤ï¼š**

1. **UI å±¤ï¼š** [pages/stream_app/chat.py:213-220](pages/stream_app/chat.py#L213-L220)
```python
request = st.chat_input("Enter your question")
if request:
    response = execute_chat(
        txt_input=request,
        context=context,
        current_session=current_session,
    )
```

2. **è™•ç†å±¤ï¼š** [open_notebook/graphs/chat.py](open_notebook/graphs/chat.py)
```python
# LangGraph èŠå¤©å·¥ä½œæµ
async def chat_node(state: ChatState) -> dict:
    # ç²å–é è¨­æ¨¡å‹
    defaults = await DefaultModels.get_instance()
    model_config = await Model.get(defaults.default_chat_model)

    # ä½¿ç”¨ Esperanto èª¿ç”¨æ¨¡å‹
    model = ChatModelLiteLLM(model=f"{model_config.provider}/{model_config.name}")
    # âŒ é€™è£¡ä½¿ç”¨äº†éŒ¯èª¤çš„åç¨±: "ollama/gtp-oss:20b"
```

3. **æ¨¡å‹å±¤ï¼š** [open_notebook/domain/models.py:122-128](open_notebook/domain/models.py#L122-L128)
```python
async def get_defaults(self) -> DefaultModels:
    if not self._default_models:
        await self.refresh_defaults()
        if not self._default_models:
            raise RuntimeError("Failed to initialize default models configuration")
    return self._default_models
```

4. **Ollama API å‘¼å«å¤±æ•—**
```bash
# å¯¦éš›ç™¼é€çš„è«‹æ±‚
POST http://localhost:11434/api/generate
{
  "model": "gtp-oss:20b"  // âŒ æ¨¡å‹ä¸å­˜åœ¨
}

# Ollama å›æ‡‰
{
  "error": "model 'gtp-oss:20b' not found"
}
```

### è§£æ±ºæ–¹æ¡ˆ

#### å¯¦æ–½æ­¥é©Ÿ

**1. åˆªé™¤æ‹¼å¯«éŒ¯èª¤çš„æ¨¡å‹ï¼ˆå·²å®Œæˆï¼‰**
```bash
curl -X DELETE \
  -H "Authorization: Bearer mapleleaf123456" \
  http://localhost:5055/api/models/model:s0azyiw39ufog3vcte7n

# {"message":"Model deleted successfully"}
```

**2. å‰µå»ºæ‹¼å¯«æ­£ç¢ºçš„æ¨¡å‹ï¼ˆå·²å®Œæˆï¼‰**
```bash
curl -X POST \
  -H "Authorization: Bearer mapleleaf123456" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "gpt-oss:20b",
    "provider": "ollama",
    "type": "language"
  }' \
  http://localhost:5055/api/models

# Response:
{
  "id": "model:rlbowbsbyxbvwi5ho6u9",
  "name": "gpt-oss:20b",  // âœ… æ­£ç¢ºæ‹¼å¯«
  "provider": "ollama",
  "type": "language",
  "created": "2025-10-20 07:33:59.529822+00:00",
  "updated": "2025-10-20 07:33:59.529823+00:00"
}
```

**3. æ›´æ–°é è¨­æ¨¡å‹é…ç½®ï¼ˆå·²å®Œæˆï¼‰**
```bash
curl -X PUT \
  -H "Authorization: Bearer mapleleaf123456" \
  -H "Content-Type: application/json" \
  -d '{
    "default_chat_model": "model:rlbowbsbyxbvwi5ho6u9",
    "default_transformation_model": "model:rlbowbsbyxbvwi5ho6u9",
    "large_context_model": "model:rlbowbsbyxbvwi5ho6u9",
    "default_text_to_speech_model": null,
    "default_speech_to_text_model": null,
    "default_embedding_model": "model:pv2kskoqa1gwb8quqnqn",
    "default_tools_model": null
  }' \
  http://localhost:5055/api/models/defaults
```

**4. é©—è­‰ Ollama æ¨¡å‹å¯è¨ªå•ï¼ˆå·²å®Œæˆï¼‰**
```bash
curl -s http://localhost:11434/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Say hello in one word",
  "stream": false
}'

# Response: {"response": "Hello", ...}
# âœ… æ¨¡å‹æ­£å¸¸é‹ä½œ
```

### é©—è­‰èˆ‡æ¸¬è©¦

#### æ¸¬è©¦æ­¥é©Ÿ

**1. é©—è­‰æ¨¡å‹é…ç½®**
```bash
# æª¢æŸ¥æ‰€æœ‰æ¨¡å‹
curl -H "Authorization: Bearer mapleleaf123456" \
  http://localhost:5055/api/models | python3 -m json.tool

# é æœŸçµæœï¼š
# [
#   {
#     "id": "model:rlbowbsbyxbvwi5ho6u9",
#     "name": "gpt-oss:20b",  // âœ… æ­£ç¢º
#     "provider": "ollama",
#     "type": "language"
#   },
#   {
#     "id": "model:pv2kskoqa1gwb8quqnqn",
#     "name": "all-MiniLM-L6-v2",
#     "provider": "ollama",
#     "type": "embedding"
#   }
# ]
```

**2. é©—è­‰é è¨­é…ç½®**
```bash
# æª¢æŸ¥é è¨­æ¨¡å‹
curl -H "Authorization: Bearer mapleleaf123456" \
  http://localhost:5055/api/models/defaults

# é æœŸçµæœï¼šæ‰€æœ‰èªè¨€æ¨¡å‹å­—æ®µæŒ‡å‘ model:rlbowbsbyxbvwi5ho6u9
```

**3. æ¸¬è©¦èŠå¤©åŠŸèƒ½**
```bash
# æ–¹æ³• 1ï¼šé€šé Streamlit UI
# 1. è¨ªå• http://localhost:8502
# 2. é€²å…¥èŠå¤©é é¢
# 3. ç™¼é€æ¸¬è©¦è¨Šæ¯
# é æœŸï¼šâœ… è¨Šæ¯æˆåŠŸç™¼é€ï¼Œæ”¶åˆ° AI å›æ‡‰

# æ–¹æ³• 2ï¼šé€šé APIï¼ˆå¦‚æœæœ‰èŠå¤©ç«¯é»ï¼‰
# curl -X POST \
#   -H "Authorization: Bearer mapleleaf123456" \
#   -H "Content-Type: application/json" \
#   -d '{"message": "Hello"}' \
#   http://localhost:5055/api/chat
```

### é é˜²æªæ–½

#### æ¨¡å‹åç¨±é©—è­‰

**1. åœ¨å‰µå»ºæ¨¡å‹æ™‚é©—è­‰åç¨±**

å»ºè­°åœ¨ API ç«¯é»ä¸­åŠ å…¥é©—è­‰ï¼š

**ä½ç½®ï¼š** [api/routers/models.py:40-71](api/routers/models.py#L40-L71)

```python
@router.post("/models", response_model=ModelResponse)
async def create_model(model_data: ModelCreate):
    """Create a new model configuration."""
    try:
        # Validate model type
        valid_types = ["language", "embedding", "text_to_speech", "speech_to_text"]
        if model_data.type not in valid_types:
            raise HTTPException(...)

        # âœ… æ–°å¢ï¼šé©—è­‰ Ollama æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if model_data.provider == "ollama":
            # Check if model exists in Ollama
            import httpx
            async with httpx.AsyncClient() as client:
                try:
                    response = await client.post(
                        "http://localhost:11434/api/show",
                        json={"name": model_data.name},
                        timeout=5.0
                    )
                    if response.status_code != 200:
                        raise HTTPException(
                            status_code=400,
                            detail=f"Model '{model_data.name}' not found in Ollama. "
                                   f"Use 'ollama list' to see available models."
                        )
                except httpx.RequestError:
                    logger.warning("Could not verify Ollama model existence (Ollama may be offline)")

        # Create model
        new_model = await Model.create(...)
```

**2. åœ¨è¨­ç½®é è¨­æ¨¡å‹æ™‚é©—è­‰**

**ä½ç½®ï¼š** [api/routers/models.py:112-128](api/routers/models.py#L112-L128)

```python
@router.put("/models/defaults", response_model=DefaultModelsResponse)
async def update_default_models(defaults_data: DefaultModelsResponse):
    """Update default model assignments."""
    try:
        # âœ… æ–°å¢ï¼šé©—è­‰æ‰€æœ‰æ¨¡å‹ ID æ˜¯å¦å­˜åœ¨
        model_ids = [
            defaults_data.default_chat_model,
            defaults_data.default_transformation_model,
            defaults_data.large_context_model,
            defaults_data.default_embedding_model,
            defaults_data.default_tools_model,
        ]

        for model_id in model_ids:
            if model_id:  # Skip None values
                model = await Model.get(model_id)
                if not model:
                    raise HTTPException(
                        status_code=404,
                        detail=f"Model {model_id} not found"
                    )

        # Update defaults
        await DefaultModels.update(...)
```

**3. å®šæœŸå¥åº·æª¢æŸ¥**

å‰µå»ºå¥åº·æª¢æŸ¥è…³æœ¬ï¼š

```bash
#!/bin/bash
# scripts/check_model_health.sh

echo "ğŸ” Checking model health..."

# Get default models
DEFAULTS=$(curl -s -H "Authorization: Bearer $OPEN_NOTEBOOK_PASSWORD" \
  http://localhost:5055/api/models/defaults)

DEFAULT_CHAT=$(echo $DEFAULTS | jq -r '.default_chat_model')

# Get model details
MODEL=$(curl -s -H "Authorization: Bearer $OPEN_NOTEBOOK_PASSWORD" \
  "http://localhost:5055/api/models/$DEFAULT_CHAT")

MODEL_NAME=$(echo $MODEL | jq -r '.name')
MODEL_PROVIDER=$(echo $MODEL | jq -r '.provider')

echo "Default chat model: $MODEL_NAME ($MODEL_PROVIDER)"

# Verify in Ollama
if [ "$MODEL_PROVIDER" = "ollama" ]; then
  if ollama list | grep -q "$MODEL_NAME"; then
    echo "âœ… Model exists in Ollama"
  else
    echo "âŒ Model NOT found in Ollama!"
    echo "Available models:"
    ollama list
    exit 1
  fi
fi
```

#### ä½¿ç”¨è€…ä»‹é¢æ”¹é€²

**Models ç®¡ç†é é¢å»ºè­°ï¼š**

1. **è‡ªå‹•ç™¼ç¾ Ollama æ¨¡å‹**
   - åŠ å…¥ã€Œå¾ Ollama å°å…¥ã€æŒ‰éˆ•
   - è‡ªå‹•åˆ—å‡º `ollama list` çš„æ‰€æœ‰æ¨¡å‹
   - ä¸€éµå°å…¥åˆ°è³‡æ–™åº«

2. **åç¨±é©—è­‰**
   - è¼¸å…¥æ¡†æä¾›è‡ªå‹•å®Œæˆ
   - å¯¦æ™‚é©—è­‰æ¨¡å‹æ˜¯å¦å­˜åœ¨
   - é¡¯ç¤ºå¯ç”¨æ¨¡å‹åˆ—è¡¨

3. **å¥åº·ç‹€æ…‹é¡¯ç¤º**
   - åœ¨æ¨¡å‹åˆ—è¡¨ä¸­é¡¯ç¤ºç‹€æ…‹æŒ‡ç¤ºå™¨
   - ç¶ è‰²ï¼šæ¨¡å‹å¯ç”¨
   - ç´…è‰²ï¼šæ¨¡å‹ä¸å­˜åœ¨æˆ–ç„¡æ³•è¨ªå•
   - é»ƒè‰²ï¼šè­¦å‘Šï¼ˆå¦‚æ¨¡å‹å·²å¸è¼‰ä½†ä»åœ¨åˆ—è¡¨ä¸­ï¼‰

### æŠ€è¡“ç´°ç¯€

#### æ¨¡å‹åç¨±è¦ç¯„

**Ollama æ¨¡å‹å‘½åæ ¼å¼ï¼š**
```
<model-name>:<tag>

ç¯„ä¾‹ï¼š
- gpt-oss:20b          âœ… æ­£ç¢º
- gtp-oss:20b          âŒ æ‹¼å¯«éŒ¯èª¤
- llama2:7b            âœ… æ­£ç¢º
- deepseek-coder-v2:16b âœ… æ­£ç¢º
```

**å¸¸è¦‹æ‹¼å¯«éŒ¯èª¤ï¼š**
- `gtp` â†” `gpt` ï¼ˆæœ€å¸¸è¦‹ï¼‰
- `lama` â†” `llama`
- `mistral` â†” `mistrial`
- `deepseek` â†” `deepseak`

#### Esperanto æ¨¡å‹èª¿ç”¨æ ¼å¼

**ä½ç½®ï¼š** LangChain/Esperanto æ•´åˆ

```python
from esperanto import ChatModelLiteLLM

# æ­£ç¢ºæ ¼å¼
model = ChatModelLiteLLM(model="ollama/gpt-oss:20b")

# éŒ¯èª¤æœƒå°è‡´
# litellm.exceptions.NotFoundError: model 'gtp-oss:20b' not found
```

#### éŒ¯èª¤å‚³æ’­è·¯å¾‘

```
UI (chat.py:213)
  â†’ execute_chat()
    â†’ LangGraph chat workflow
      â†’ DefaultModels.get_instance()
        â†’ Model.get(default_chat_model)
          â†’ Esperanto ChatModelLiteLLM
            â†’ LiteLLM
              â†’ Ollama API
                âŒ Error: Model not found
              â† Exception propagates back
            â† RuntimeError
          â† Failed to send message
        â† UI displays error
      â† User sees "Failed to send message"
```

### ç›¸é—œæª”æ¡ˆ

**ä¿®æ”¹çš„è³‡æºï¼š**
- è³‡æ–™åº«è¨˜éŒ„ï¼š`model:s0azyiw39ufog3vcte7n` â†’ å·²åˆªé™¤
- è³‡æ–™åº«è¨˜éŒ„ï¼š`model:rlbowbsbyxbvwi5ho6u9` â†’ æ–°å»ºï¼ˆæ­£ç¢ºåç¨±ï¼‰
- è³‡æ–™åº«è¨˜éŒ„ï¼š`open_notebook:default_models` â†’ å·²æ›´æ–°

**æ¶‰åŠçš„ä»£ç¢¼ï¼š**
- [pages/stream_app/chat.py](pages/stream_app/chat.py) - UI å±¤
- [open_notebook/graphs/chat.py](open_notebook/graphs/chat.py) - è™•ç†å±¤
- [open_notebook/domain/models.py](open_notebook/domain/models.py) - æ¨¡å‹ç®¡ç†
- [api/routers/models.py](api/routers/models.py) - API ç«¯é»

### ç¶“é©—æ•™è¨“

#### é—œéµåŸå‰‡

1. **é…ç½®é©—è­‰**
   - åœ¨å‰µå»ºé…ç½®æ™‚é©—è­‰å…¶æ­£ç¢ºæ€§
   - ä¸è¦å‡è¨­ä½¿ç”¨è€…è¼¸å…¥ç¸½æ˜¯æ­£ç¢ºçš„
   - æä¾›å¯¦æ™‚åé¥‹å’Œé©—è­‰

2. **éŒ¯èª¤è¨Šæ¯æ”¹é€²**
   - "Failed to send message" éæ–¼ç± çµ±
   - æ‡‰è©²é¡¯ç¤ºå…·é«”éŒ¯èª¤ï¼šã€Œæ¨¡å‹ 'gtp-oss:20b' åœ¨ Ollama ä¸­ä¸å­˜åœ¨ã€
   - æä¾›å¯æ“ä½œçš„å»ºè­°

3. **è‡ªå‹•åŒ–æª¢æ¸¬**
   - å®šæœŸå¥åº·æª¢æŸ¥
   - å•Ÿå‹•æ™‚é©—è­‰é…ç½®
   - æä¾›è¨ºæ–·å·¥å…·

4. **ä½¿ç”¨è€…é«”é©—**
   - å¾å¯ç”¨é¸é …ä¸­é¸æ“‡ï¼ˆä¸‹æ‹‰é¸å–®ï¼‰æ¯”æ‰‹å‹•è¼¸å…¥æ›´å¯é 
   - è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶æ¸›å°‘é…ç½®éŒ¯èª¤
   - ç‹€æ…‹æŒ‡ç¤ºå™¨æä¾›å³æ™‚åé¥‹

### ç¸½çµ

#### æ ¸å¿ƒå•é¡Œ
è³‡æ–™åº«ä¸­é…ç½®çš„æ¨¡å‹åç¨± `gtp-oss:20b` æ˜¯æ‹¼å¯«éŒ¯èª¤ï¼ŒOllama ä¸­å¯¦éš›çš„æ¨¡å‹åç¨±æ˜¯ `gpt-oss:20b`ï¼ˆgtp â†’ gptï¼‰ã€‚

#### è§£æ±ºæ–¹æ¡ˆ
1. âœ… åˆªé™¤æ‹¼å¯«éŒ¯èª¤çš„æ¨¡å‹è¨˜éŒ„
2. âœ… å‰µå»ºæ‹¼å¯«æ­£ç¢ºçš„æ¨¡å‹è¨˜éŒ„
3. âœ… æ›´æ–°é è¨­æ¨¡å‹é…ç½®æŒ‡å‘æ–°è¨˜éŒ„
4. âœ… é©—è­‰ Ollama å¯ä»¥æ­£å¸¸è¨ªå•æ¨¡å‹

#### çµæœ
âœ… æ¨¡å‹é…ç½®ç¾åœ¨èˆ‡ Ollama ä¸­çš„å¯¦éš›æ¨¡å‹åç¨±åŒ¹é…
âœ… èŠå¤©åŠŸèƒ½æ‡‰è©²å¯ä»¥æ­£å¸¸å·¥ä½œ
âœ… é è¨­æ¨¡å‹é…ç½®å·²æ›´æ–°ç‚ºæ­£ç¢ºçš„æ¨¡å‹ ID

#### æ ¹æœ¬åŸå› 
æ‰‹å‹•è¼¸å…¥é…ç½®æ™‚çš„æ‹¼å¯«éŒ¯èª¤ï¼Œç¼ºä¹é©—è­‰æ©Ÿåˆ¶ä¾†æª¢æ¸¬é…ç½®èˆ‡å¯¦éš›å¯ç”¨è³‡æºçš„ä¸åŒ¹é…ã€‚

#### å»ºè­°æ”¹é€²
1. API ç«¯é»åŠ å…¥æ¨¡å‹åç¨±é©—è­‰
2. UI æä¾›è‡ªå‹•ç™¼ç¾å’Œé¸æ“‡åŠŸèƒ½
3. å¯¦æ–½å®šæœŸå¥åº·æª¢æŸ¥
4. æ”¹é€²éŒ¯èª¤è¨Šæ¯çš„å…·é«”æ€§å’Œå¯æ“ä½œæ€§

#### ä¸‹ä¸€æ­¥
ä½¿ç”¨è€…æ‡‰è©²æ¸¬è©¦èŠå¤©åŠŸèƒ½ç¢ºèªå•é¡Œå·²è§£æ±ºï¼š
```bash
# å•Ÿå‹• Streamlit UIï¼ˆå¦‚æœæœªé‹è¡Œï¼‰
cd /home/mapleleaf/LCJRepos/projects/lcj_open_notebook
uv run --env-file .env streamlit run app_home.py

# è¨ªå• http://localhost:8502
# é€²å…¥èŠå¤©é é¢ä¸¦ç™¼é€æ¸¬è©¦è¨Šæ¯
```

---

## é™„éŒ„ï¼šstop_system_improved.sh å‰µå»º

### å•é¡Œè­˜åˆ¥

ä½¿ç”¨è€…æå•ï¼šã€ŒIs it necessary to modify stop_system.sh since we create start_system_improved.sh?ã€

### åˆ†æçµæœ

**æ˜¯çš„ï¼Œéœ€è¦å‰µå»ºå°æ‡‰çš„æ”¹é€²ç‰ˆæœ¬ï¼**

#### çµ„ä»¶å·®ç•°å°æ¯”

**start_system_improved.sh å•Ÿå‹•çš„çµ„ä»¶ï¼š**
1. SurrealDB (Docker container)
2. API Backend (`.api.pid`)
3. **Background Worker (`.worker.pid`)** â† æ–°å¢çµ„ä»¶
4. Streamlit UI (`.streamlit.pid`)

**stop_system.sh åœæ­¢çš„çµ„ä»¶ï¼š**
1. Streamlit UI (`.streamlit.pid`)
2. API Backend (`.api.pid`)
3. SurrealDB (Docker container)
4. âŒ **ç¼ºå°‘ Worker åœæ­¢é‚è¼¯** â† å•é¡Œ

#### æ½›åœ¨å•é¡Œ

å¦‚æœä½¿ç”¨ä¸åŒ¹é…çš„å•Ÿå‹•/åœæ­¢è…³æœ¬ï¼š

```bash
# å•Ÿå‹•ç³»çµ±ï¼ˆåŒ…å« Workerï¼‰
./start_system_improved.sh

# ä½¿ç”¨èˆŠè…³æœ¬åœæ­¢ï¼ˆç¼ºå°‘ Workerï¼‰
./stop_system.sh

# çµæœï¼šWorker é€²ç¨‹ç¹¼çºŒé‹è¡Œï¼
pgrep -f "surreal-commands-worker"  # âš ï¸  Still running
```

**å¾Œæœï¼š**
- âŒ Worker é€²ç¨‹æ´©æ¼ï¼ˆæŒçºŒæ¶ˆè€—è¨˜æ†¶é«”å’Œè³‡æºï¼‰
- âŒ ä¸‹æ¬¡å•Ÿå‹•æ™‚ç«¯å£è¡çªæˆ–é€²ç¨‹è¡çª
- âŒ ç„¡æ³•å®Œå…¨åœæ­¢ç³»çµ±
- âŒ å¯èƒ½å°è‡´è³‡æ–™åº«é€£æ¥ä¿æŒé–‹å•Ÿ

### è§£æ±ºæ–¹æ¡ˆ

å‰µå»º `stop_system_improved.sh` ä»¥åŒ¹é… `start_system_improved.sh`ã€‚

#### æ–°å¢åŠŸèƒ½

**1. Worker åœæ­¢é‚è¼¯**
```bash
# Stop Background Worker
stop_process "Background Worker" ".worker.pid" "âš™ï¸"

# Alternative: Kill by process name if PID file missing
if pgrep -f "surreal-commands-worker" > /dev/null; then
    echo "âš™ï¸  Found Worker by process name, stopping..."
    pkill -f "surreal-commands-worker" || true
    sleep 1
    echo "âœ… Worker stopped"
fi
```

**2. å„ªé›…åœæ­¢å‡½æ•¸**
```bash
stop_process() {
    local NAME=$1
    local PID_FILE=$2
    local EMOJI=$3

    if [ -f "$PID_FILE" ]; then
        PID=$(cat "$PID_FILE")
        if ps -p $PID > /dev/null 2>&1; then
            # Try graceful shutdown first
            kill $PID 2>/dev/null || true

            # Wait up to 5 seconds
            for i in {1..5}; do
                if ! ps -p $PID > /dev/null 2>&1; then
                    break
                fi
                sleep 1
            done

            # Force kill if still running
            if ps -p $PID > /dev/null 2>&1; then
                kill -9 $PID 2>/dev/null || true
            fi

            rm "$PID_FILE"
            echo "âœ… $NAME stopped"
        fi
    fi
}
```

**3. å­¤å…’é€²ç¨‹æ¸…ç†**
```bash
# Check for any orphaned processes
if pgrep -f "uvicorn api.main:app" > /dev/null; then
    echo "âš ï¸  Found orphaned API processes, cleaning up..."
    pkill -f "uvicorn api.main:app" || true
fi

if pgrep -f "streamlit run app_home.py" > /dev/null; then
    echo "âš ï¸  Found orphaned Streamlit processes, cleaning up..."
    pkill -f "streamlit run app_home.py" || true
fi

if pgrep -f "surreal-commands-worker" > /dev/null; then
    echo "âš ï¸  Found orphaned Worker processes, cleaning up..."
    pkill -f "surreal-commands-worker" || true
fi
```

**4. åœæ­¢å¾Œç‹€æ…‹æª¢æŸ¥**
```bash
echo "ğŸ“Š System Status:"
echo "   - SurrealDB: $(docker ps | grep -q 'lcj_open_notebook-surrealdb' && echo 'âŒ Stopped' || echo 'âœ… Not running')"
echo "   - API:       $(pgrep -f 'uvicorn api.main:app' > /dev/null && echo 'âš ï¸  Still running!' || echo 'âœ… Stopped')"
echo "   - Worker:    $(pgrep -f 'surreal-commands-worker' > /dev/null && echo 'âš ï¸  Still running!' || echo 'âœ… Stopped')"
echo "   - Streamlit: $(pgrep -f 'streamlit run app_home.py' > /dev/null && echo 'âš ï¸  Still running!' || echo 'âœ… Stopped')"
```

### æª”æ¡ˆè©³æƒ…

**ä½ç½®ï¼š** [stop_system_improved.sh](stop_system_improved.sh)

**æ¬Šé™ï¼š** `chmod +x stop_system_improved.sh` âœ… å·²è¨­ç½®

**åœæ­¢é †åºï¼š**
1. Streamlit UIï¼ˆå‰ç«¯ï¼Œæœ€å…ˆåœæ­¢é¿å…ç”¨æˆ¶éŒ¯èª¤ï¼‰
2. Background Workerï¼ˆè™•ç†å±¤ï¼Œåœæ­¢èƒŒæ™¯ä»»å‹™ï¼‰
3. API Backendï¼ˆå¾Œç«¯æœå‹™ï¼‰
4. SurrealDBï¼ˆè³‡æ–™åº«ï¼Œæœ€å¾Œåœæ­¢ç¢ºä¿æ•¸æ“šå®Œæ•´æ€§ï¼‰

### ä½¿ç”¨æ–¹å¼

**å•Ÿå‹•ç³»çµ±ï¼š**
```bash
./start_system_improved.sh
```

**åœæ­¢ç³»çµ±ï¼š**
```bash
./stop_system_improved.sh
```

**è¼¸å‡ºç¤ºä¾‹ï¼š**
```
ğŸ›‘ Stopping Open Notebook System...

ğŸ¨ Stopping Streamlit UI (PID: 12345)...
âœ… Streamlit UI stopped

âš™ï¸  Stopping Background Worker (PID: 12346)...
âœ… Background Worker stopped

ğŸ”§ Stopping API Backend (PID: 12347)...
âœ… API Backend stopped

ğŸ“Š Stopping SurrealDB...
âœ… SurrealDB stopped

ğŸ§¹ Cleaning up...

âœ¨ Open Notebook System Stopped!

ğŸ“Š System Status:
   - SurrealDB: âœ… Not running
   - API:       âœ… Stopped
   - Worker:    âœ… Stopped
   - Streamlit: âœ… Stopped

ğŸš€ Restart: ./start_system_improved.sh
```

### é©—è­‰æ¸¬è©¦

**æ¸¬è©¦å®Œæ•´å•Ÿå‹•/åœæ­¢å¾ªç’°ï¼š**
```bash
# 1. å•Ÿå‹•ç³»çµ±
./start_system_improved.sh

# 2. é©—è­‰æ‰€æœ‰çµ„ä»¶é‹è¡Œ
pgrep -f "uvicorn api.main:app"        # API running
pgrep -f "surreal-commands-worker"     # Worker running
pgrep -f "streamlit run app_home.py"   # UI running
docker ps | grep surrealdb             # DB running

# 3. åœæ­¢ç³»çµ±
./stop_system_improved.sh

# 4. é©—è­‰æ‰€æœ‰çµ„ä»¶å·²åœæ­¢
pgrep -f "uvicorn api.main:app"        # (no output)
pgrep -f "surreal-commands-worker"     # (no output)
pgrep -f "streamlit run app_home.py"   # (no output)
docker ps | grep surrealdb             # (no output)
```

### é—œéµæ”¹é€²é»

**ç›¸æ¯” stop_system.shï¼š**

1. âœ… **å®Œæ•´çµ„ä»¶è¦†è“‹** - åŒ…å« Worker åœæ­¢é‚è¼¯
2. âœ… **å„ªé›…åœæ­¢** - å…ˆå˜—è©¦ SIGTERMï¼Œå¤±æ•—å¾Œæ‰ SIGKILL
3. âœ… **å­¤å…’æ¸…ç†** - æª¢æ¸¬ä¸¦æ¸…ç†æ®˜ç•™é€²ç¨‹
4. âœ… **ç‹€æ…‹å ±å‘Š** - åœæ­¢å¾Œé¡¯ç¤ºæ¯å€‹çµ„ä»¶ç‹€æ…‹
5. âœ… **éŒ¯èª¤è™•ç†** - æ›´å¥å£¯çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
6. âœ… **é€²ç¨‹åå›é€€** - å¦‚æœ PID æ–‡ä»¶ä¸Ÿå¤±ï¼Œä½¿ç”¨é€²ç¨‹åç¨±æŸ¥æ‰¾

### æœ€ä½³å¯¦è¸

**æˆå°ä½¿ç”¨è…³æœ¬ï¼š**
```bash
# âœ… æ­£ç¢º
./start_system_improved.sh
./stop_system_improved.sh

# âŒ éŒ¯èª¤ï¼ˆçµ„ä»¶ä¸åŒ¹é…ï¼‰
./start_system_improved.sh
./stop_system.sh          # ç¼ºå°‘ Worker åœæ­¢
```

**æª¢æŸ¥ç³»çµ±ç‹€æ…‹ï¼š**
```bash
# å¿«é€Ÿæª¢æŸ¥æ‰€æœ‰çµ„ä»¶
pgrep -af "uvicorn|streamlit|surreal-commands-worker" | grep -v grep
docker ps | grep surrealdb
```

**æ¸…ç†æ®˜ç•™é€²ç¨‹ï¼š**
```bash
# å¦‚æœåœæ­¢è…³æœ¬å¤±æ•—ï¼Œæ‰‹å‹•æ¸…ç†
pkill -f "uvicorn api.main:app"
pkill -f "streamlit run app_home.py"
pkill -f "surreal-commands-worker"
docker compose stop surrealdb
```

### ç¸½çµ

#### æ ¸å¿ƒåŸå› 
`start_system_improved.sh` å•Ÿå‹•äº† Worker çµ„ä»¶ï¼Œä½†åŸå§‹çš„ `stop_system.sh` ä¸åŒ…å«å°æ‡‰çš„åœæ­¢é‚è¼¯ï¼Œå°è‡´é€²ç¨‹æ´©æ¼ã€‚

#### è§£æ±ºæ–¹æ¡ˆ
å‰µå»º `stop_system_improved.sh` ä»¥åŒ¹é…æ”¹é€²çš„å•Ÿå‹•è…³æœ¬ï¼Œç¢ºä¿æ‰€æœ‰å•Ÿå‹•çš„çµ„ä»¶éƒ½èƒ½è¢«æ­£ç¢ºåœæ­¢ã€‚

#### çµæœ
âœ… å®Œæ•´çš„å•Ÿå‹•/åœæ­¢é…å°
âœ… æ‰€æœ‰çµ„ä»¶ï¼ˆåŒ…å« Workerï¼‰éƒ½èƒ½æ­£ç¢ºåœæ­¢
âœ… å„ªé›…åœæ­¢æ©Ÿåˆ¶å’Œå­¤å…’é€²ç¨‹æ¸…ç†
âœ… åœæ­¢å¾Œç‹€æ…‹é©—è­‰

#### å»ºè­°
å§‹çµ‚ä½¿ç”¨åŒ¹é…çš„å•Ÿå‹•/åœæ­¢è…³æœ¬å°ï¼Œé¿å…çµ„ä»¶ä¸ä¸€è‡´å°è‡´çš„è³‡æºæ´©æ¼ã€‚

---

---

## å•é¡Œ 8ï¼šèŠå¤©è¨Šæ¯é‡è¤‡æäº¤ - ç¼ºå°‘éŒ¯èª¤è™•ç†å’Œå›æ»¾æ©Ÿåˆ¶

### å•é¡Œæè¿°

ä½¿ç”¨è€…å ±å‘Šï¼šæŸ¥è©¢ "give me a summary of the book" å¾Œï¼Œç³»çµ±é¡¯ç¤º "Failed to send message"ï¼Œä½†åœ¨èŠå¤©ä»‹é¢ä¸­çœ‹åˆ°**ç›¸åŒè¨Šæ¯é‡è¤‡å‡ºç¾ 7 æ¬¡**ã€‚

**æˆªåœ–è­‰æ“šï¼š**
- [error_02_20251020.png](docs/errorsimages/error_02_20251020.png) - é¡¯ç¤º 7 å€‹é‡è¤‡çš„ç”¨æˆ¶è¨Šæ¯
- [error_01_20251020.png](docs/errorsimages/error_01_20251020.png) - é¡¯ç¤º "Failed to send message" éŒ¯èª¤

**é—œéµè§€å¯Ÿï¼š**
- âœ… æ¨¡å‹é…ç½®æ­£ç¢ºï¼šåº•éƒ¨é¡¯ç¤º `gpt-oss:20b`ï¼ˆä¹‹å‰å·²ä¿®å¾©ï¼‰
- âœ… ä¸Šä¸‹æ–‡å­˜åœ¨ï¼šContext: 1 source, 132.1K tokens / 583.2K chars
- âŒ è¨Šæ¯é‡è¤‡ï¼šç›¸åŒæŸ¥è©¢å‡ºç¾ 7 æ¬¡
- âŒ éŒ¯èª¤è¨Šæ¯ç± çµ±ï¼š"Failed to send message"

### æ ¹æœ¬åŸå› åˆ†æ

#### ä»£ç¢¼æµç¨‹å•é¡Œ

**ä½ç½®ï¼š** [pages/stream_app/chat.py:57-66](pages/stream_app/chat.py#L57-L66)

**åŸå§‹ä»£ç¢¼ï¼š**
```python
def execute_chat(txt_input, context, current_session):
    current_state = st.session_state[current_session.id]
    current_state["messages"] += [txt_input]  # â† è¨Šæ¯ç«‹å³æ·»åŠ ï¼
    current_state["context"] = context
    result = chat_graph.invoke(              # â† å¦‚æœé€™è£¡å¤±æ•—...
        input=current_state,
        config=RunnableConfig(configurable={"thread_id": current_session.id}),
    )
    current_session.save()
    return result  # â† ...æ°¸é ä¸æœƒåˆ°é”é€™è£¡
```

**è‡´å‘½ç¼ºé™·ï¼š**
1. **è¨Šæ¯æå‰æäº¤**ï¼šLine 59 ç«‹å³å°‡è¨Šæ¯æ·»åŠ åˆ° `messages` åˆ—è¡¨
2. **ç„¡éŒ¯èª¤è™•ç†**ï¼šå¦‚æœ `chat_graph.invoke()` æ‹‹å‡ºç•°å¸¸
3. **ç„¡å›æ»¾æ©Ÿåˆ¶**ï¼šè¨Šæ¯å·²ä¿å­˜åœ¨ session state
4. **ç„¡ç”¨æˆ¶åé¥‹**ï¼šåªé¡¯ç¤ºç± çµ±çš„ "Failed to send message"

#### å¤±æ•—å¾ªç’°

```
å˜—è©¦ 1:
  â””â”€ æ·»åŠ è¨Šæ¯åˆ° messages[] â†’ [msg1]
     â””â”€ chat_graph.invoke() â†’ âŒ å¤±æ•—ï¼ˆä¾‹å¦‚ï¼šä¸Šä¸‹æ–‡å¤ªå¤§ï¼‰
        â””â”€ ç•°å¸¸æ‹‹å‡º
           â””â”€ è¨Šæ¯ä¿ç•™åœ¨åˆ—è¡¨ä¸­
              â””â”€ é¡¯ç¤º "Failed to send message"

å˜—è©¦ 2 (ç”¨æˆ¶é‡è©¦):
  â””â”€ æ·»åŠ è¨Šæ¯åˆ° messages[] â†’ [msg1, msg1]  â† é‡è¤‡ï¼
     â””â”€ chat_graph.invoke() â†’ âŒ å†æ¬¡å¤±æ•—
        â””â”€ è¨Šæ¯å†æ¬¡ä¿ç•™

å˜—è©¦ 3-7:
  â””â”€ æŒçºŒé‡è¤‡...
     â””â”€ [msg1, msg1, msg1, msg1, msg1, msg1, msg1]  â† 7 å€‹é‡è¤‡ï¼
```

#### å¯èƒ½çš„å¯¦éš›å¤±æ•—åŸå› 

åŸºæ–¼ä¸Šä¸‹æ–‡å¤§å°ï¼ˆ**132.1K tokens / 583.2K chars**ï¼‰ï¼Œæœ€å¯èƒ½çš„åŸå› ï¼š

**1. ä¸Šä¸‹æ–‡é•·åº¦è¶…é™**
```python
# å¯èƒ½çš„éŒ¯èª¤
litellm.exceptions.ContextLengthExceededError:
  Context length exceeded: requested 132100 tokens, max 8192
```

**2. Ollama è¨˜æ†¶é«”ä¸è¶³**
```
# gpt-oss:20b éœ€è¦ç´„ 13-14GB RAM
# åŠ ä¸Š 132K tokens ä¸Šä¸‹æ–‡ â†’ å¯èƒ½è¶…å‡ºå¯ç”¨è¨˜æ†¶é«”
```

**3. è«‹æ±‚è¶…æ™‚**
```python
# è™•ç† 132K tokens å¯èƒ½éœ€è¦å¾ˆé•·æ™‚é–“
httpx.ReadTimeout: Request timeout after 120s
```

### è§£æ±ºæ–¹æ¡ˆ

#### å¯¦æ–½çš„ä¿®å¾©

**1. æ·»åŠ éŒ¯èª¤è™•ç†å’Œå›æ»¾æ©Ÿåˆ¶**

**ä½ç½®ï¼š** [pages/stream_app/chat.py:57-91](pages/stream_app/chat.py#L57-L91)

```python
def execute_chat(txt_input, context, current_session):
    current_state = st.session_state[current_session.id]

    # âœ… æ–°å¢ï¼šä¿å­˜åŸå§‹ç‹€æ…‹ç”¨æ–¼å›æ»¾
    original_messages = current_state["messages"].copy()

    try:
        current_state["messages"] += [txt_input]
        current_state["context"] = context
        result = chat_graph.invoke(
            input=current_state,
            config=RunnableConfig(configurable={"thread_id": current_session.id}),
        )
        current_session.save()
        return result
    except Exception as e:
        # âœ… æ–°å¢ï¼šç™¼ç”ŸéŒ¯èª¤æ™‚å›æ»¾è¨Šæ¯
        current_state["messages"] = original_messages
        logger.error(f"Chat execution failed: {type(e).__name__}: {str(e)}")

        # âœ… æ–°å¢ï¼šç”¨æˆ¶å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
        error_msg = str(e)
        if "context_length_exceeded" in error_msg.lower() or "too long" in error_msg.lower():
            raise RuntimeError(
                f"Context too large ({len(str(context))} chars). "
                "Please reduce the number of sources or notes in your context."
            ) from e
        elif "model" in error_msg.lower() and "not found" in error_msg.lower():
            raise RuntimeError(
                f"Model not available. Please check your model configuration in Settings."
            ) from e
        else:
            raise RuntimeError(
                f"Failed to send message: {type(e).__name__}: {str(e)[:100]}"
            ) from e
```

**2. æ·»åŠ ç”¨æˆ¶ç•Œé¢éŒ¯èª¤é¡¯ç¤º**

**ä½ç½®ï¼š** [pages/stream_app/chat.py:237-251](pages/stream_app/chat.py#L237-L251)

```python
with st.container(border=True):
    request = st.chat_input("Enter your question")
    if request:
        try:  # âœ… æ–°å¢ï¼štry-except åŒ…è£¹
            response = execute_chat(
                txt_input=request,
                context=context,
                current_session=current_session,
            )
            st.session_state[current_session.id]["messages"] = response["messages"]
        except Exception as e:
            # âœ… æ–°å¢ï¼šå‘ç”¨æˆ¶é¡¯ç¤ºå…·é«”éŒ¯èª¤
            st.error(f"âŒ {str(e)}")
            logger.error(f"Chat error displayed to user: {e}")
```

### ä¿®å¾©æ•ˆæœ

#### ä¿®å¾©å‰ï¼ˆå•é¡Œè¡Œç‚ºï¼‰

```
ç”¨æˆ¶ï¼šæäº¤æŸ¥è©¢
  â†“
è¨Šæ¯æ·»åŠ åˆ°åˆ—è¡¨ [msg]
  â†“
è™•ç†å¤±æ•— âŒ
  â†“
è¨Šæ¯ä¿ç•™ [msg]
  â†“
é¡¯ç¤º "Failed to send message"ï¼ˆç± çµ±ï¼‰
  â†“
ç”¨æˆ¶é‡è©¦
  â†“
è¨Šæ¯å†æ¬¡æ·»åŠ  [msg, msg]
  â†“
é‡è¤‡ 7 æ¬¡ â†’ [msg, msg, msg, msg, msg, msg, msg]
```

#### ä¿®å¾©å¾Œï¼ˆé æœŸè¡Œç‚ºï¼‰

```
ç”¨æˆ¶ï¼šæäº¤æŸ¥è©¢
  â†“
ä¿å­˜åŸå§‹ç‹€æ…‹ backup = []
  â†“
è¨Šæ¯æ·»åŠ åˆ°åˆ—è¡¨ [msg]
  â†“
è™•ç†å¤±æ•— âŒ
  â†“
å›æ»¾åˆ°åŸå§‹ç‹€æ…‹ [] â† è¨Šæ¯ç§»é™¤
  â†“
é¡¯ç¤ºå…·é«”éŒ¯èª¤ï¼š
  "âŒ Context too large (583200 chars).
   Please reduce the number of sources or notes in your context."
  â†“
ç”¨æˆ¶ç†è§£å•é¡Œï¼Œæ¸›å°‘ä¸Šä¸‹æ–‡
  â†“
é‡è©¦æˆåŠŸ âœ…
```

### éŒ¯èª¤åˆ†é¡å’Œè¨Šæ¯

ä¿®å¾©å¾Œçš„éŒ¯èª¤è™•ç†æä¾›ä¸‰ç¨®å…·é«”è¨Šæ¯ï¼š

**1. ä¸Šä¸‹æ–‡å¤ªå¤§**
```
âŒ Context too large (583200 chars).
Please reduce the number of sources or notes in your context.
```

**2. æ¨¡å‹ä¸å¯ç”¨**
```
âŒ Model not available.
Please check your model configuration in Settings.
```

**3. å…¶ä»–éŒ¯èª¤**
```
âŒ Failed to send message: ValueError: Invalid input format
```

### é©—è­‰æ¸¬è©¦

#### æ¸¬è©¦å ´æ™¯ 1ï¼šä¸Šä¸‹æ–‡å¤ªå¤§

**æ­¥é©Ÿï¼š**
```bash
1. åœ¨ Notebook ä¸­æ·»åŠ å¤§é‡ sourcesï¼ˆä½¿ä¸Šä¸‹æ–‡è¶…éæ¨¡å‹é™åˆ¶ï¼‰
2. å˜—è©¦ç™¼é€èŠå¤©è¨Šæ¯
3. è§€å¯ŸéŒ¯èª¤è¨Šæ¯
4. æ¸›å°‘ sources æ•¸é‡
5. é‡è©¦
```

**é æœŸçµæœï¼š**
- âŒ ç¬¬ä¸€æ¬¡å¤±æ•—ï¼Œé¡¯ç¤ºå…·é«”éŒ¯èª¤
- âœ… è¨Šæ¯**ä¸æœƒ**é‡è¤‡å‡ºç¾
- âœ… æ¸›å°‘ä¸Šä¸‹æ–‡å¾ŒæˆåŠŸ

#### æ¸¬è©¦å ´æ™¯ 2ï¼šæ¨¡å‹éŒ¯èª¤

**æ­¥é©Ÿï¼š**
```bash
# æ•…æ„é…ç½®éŒ¯èª¤çš„æ¨¡å‹åç¨±
curl -X DELETE -H "Authorization: Bearer mapleleaf123456" \
  http://localhost:5055/api/models/model:rlbowbsbyxbvwi5ho6u9

# å˜—è©¦èŠå¤©
# æ‡‰è©²çœ‹åˆ°æ¸…æ™°çš„éŒ¯èª¤è¨Šæ¯
```

**é æœŸçµæœï¼š**
- âŒ é¡¯ç¤º "Model not available" éŒ¯èª¤
- âœ… è¨Šæ¯ä¸é‡è¤‡
- âœ… ç”¨æˆ¶çŸ¥é“å» Settings ä¿®å¾©

#### æ¸¬è©¦å ´æ™¯ 3ï¼šç¶²çµ¡è¶…æ™‚

**æ­¥é©Ÿï¼š**
```bash
# æš«æ™‚åœæ­¢ Ollama
sudo systemctl stop ollama

# å˜—è©¦èŠå¤©

# é‡å•Ÿ Ollama
sudo systemctl start ollama
```

**é æœŸçµæœï¼š**
- âŒ é¡¯ç¤ºé€£æ¥éŒ¯èª¤
- âœ… è¨Šæ¯ä¸é‡è¤‡
- âœ… Ollama é‡å•Ÿå¾Œå¯ä»¥é‡è©¦

### é é˜²æªæ–½

#### 1. ä¸Šä¸‹æ–‡å¤§å°è­¦å‘Š

**å»ºè­°åœ¨ UI ä¸­æ·»åŠ ï¼š**

```python
# pages/stream_app/chat.py
def chat_sidebar(current_notebook: Notebook, current_session: ChatSession):
    context = build_context(notebook_id=current_notebook.id)
    tokens = token_count(str(context))

    # âœ… æ·»åŠ è­¦å‘Š
    if tokens > 100000:  # 100K tokens
        st.warning(
            f"âš ï¸ Large context ({tokens:,} tokens). "
            "This may cause performance issues or failures. "
            "Consider reducing sources/notes."
        )

    with st.expander(f"Context ({tokens} tokens), {len(str(context))} chars"):
        st.json(context)
```

#### 2. è‡ªå‹•ä¸Šä¸‹æ–‡é™åˆ¶

**å»ºè­°åœ¨ chat_graph ä¸­æ·»åŠ ï¼š**

```python
# open_notebook/graphs/chat.py
async def chat_node(state: ChatState) -> dict:
    context = state["context"]
    context_str = str(context)

    # âœ… æª¢æŸ¥ä¸Šä¸‹æ–‡å¤§å°
    MAX_CONTEXT_CHARS = 500000  # 500K characters
    if len(context_str) > MAX_CONTEXT_CHARS:
        raise ValueError(
            f"Context too large: {len(context_str)} chars "
            f"(max: {MAX_CONTEXT_CHARS}). "
            "Please reduce sources or notes."
        )

    # ç¹¼çºŒè™•ç†...
```

#### 3. é‡è©¦é‚è¼¯

**å¯é¸ï¼šæ·»åŠ æ™ºèƒ½é‡è©¦**

```python
# pages/stream_app/chat.py
def execute_chat_with_retry(txt_input, context, current_session, max_retries=3):
    for attempt in range(max_retries):
        try:
            return execute_chat(txt_input, context, current_session)
        except httpx.ReadTimeout:
            if attempt < max_retries - 1:
                logger.warning(f"Timeout on attempt {attempt + 1}, retrying...")
                time.sleep(2 ** attempt)  # Exponential backoff
            else:
                raise
        except Exception:
            raise  # Don't retry other errors
```

### æŠ€è¡“ç´°ç¯€

#### å›æ»¾æ©Ÿåˆ¶çš„é‡è¦æ€§

**ç‚ºä»€éº¼éœ€è¦ `.copy()`ï¼š**
```python
# âŒ éŒ¯èª¤ï¼šæ·ºæ‹·è²å¼•ç”¨
original_messages = current_state["messages"]
current_state["messages"] += [txt_input]
# å•é¡Œï¼šoriginal_messages å’Œ current_state["messages"] æŒ‡å‘åŒä¸€å€‹åˆ—è¡¨ï¼

# âœ… æ­£ç¢ºï¼šæ·±æ‹·è²å€¼
original_messages = current_state["messages"].copy()
current_state["messages"] += [txt_input]
# ç¾åœ¨ original_messages æ˜¯ç¨ç«‹çš„å‰¯æœ¬
```

#### Streamlit ç‹€æ…‹ç®¡ç†

**Session State ç‰¹æ€§ï¼š**
- ç‹€æ…‹åœ¨ç”¨æˆ¶æœƒè©±æœŸé–“æŒä¹…åŒ–
- éŒ¯èª¤å¾Œç‹€æ…‹**ä¸æœƒ**è‡ªå‹•å›æ»¾
- å¿…é ˆæ‰‹å‹•ç®¡ç†ç‹€æ…‹ä¸€è‡´æ€§

**é é¢é‡æ–°é‹è¡Œè¡Œç‚ºï¼š**
```python
if request:
    try:
        execute_chat(...)  # å¯èƒ½å¤±æ•—
    except Exception as e:
        st.error(str(e))    # é¡¯ç¤ºéŒ¯èª¤
        # Streamlit ç¹¼çºŒé‹è¡Œï¼Œé¡¯ç¤ºç•¶å‰ç‹€æ…‹
        # å¦‚æœæ²’æœ‰å›æ»¾ï¼ŒéŒ¯èª¤çš„è¨Šæ¯æœƒé¡¯ç¤º
```

#### éŒ¯èª¤å‚³æ’­è·¯å¾‘

```
UI (chat.py:241) â†’ execute_chat()
  â†“
chat_graph.invoke()
  â†“
LangGraph chat workflow
  â†“
Model invocation (Esperanto/LiteLLM)
  â†“
Ollama API call
  â†“
âŒ Error (e.g., context_length_exceeded)
  â†“
Exception propagates back
  â†“
Caught in execute_chat() â†’ Rollback
  â†“
Re-raised with user-friendly message
  â†“
Caught in UI â†’ st.error() displays to user
```

### ç›¸é—œæª”æ¡ˆ

**ä¿®æ”¹çš„æª”æ¡ˆï¼š**
- [pages/stream_app/chat.py](pages/stream_app/chat.py) - æ·»åŠ éŒ¯èª¤è™•ç†å’Œå›æ»¾æ©Ÿåˆ¶

**ä¿®æ”¹å…§å®¹ï¼š**
1. `execute_chat()` å‡½æ•¸ (lines 57-91)
   - æ·»åŠ  try-except å¡Š
   - è¨Šæ¯åˆ—è¡¨å›æ»¾æ©Ÿåˆ¶
   - å…·é«”éŒ¯èª¤è¨Šæ¯åˆ†é¡

2. èŠå¤©è¼¸å…¥è™•ç† (lines 237-251)
   - æ·»åŠ  try-except åŒ…è£
   - ä½¿ç”¨ `st.error()` é¡¯ç¤ºéŒ¯èª¤

### ç¶“é©—æ•™è¨“

#### é—œéµåŸå‰‡

1. **åŸå­æ€§æ“ä½œ**
   - ç‹€æ…‹ä¿®æ”¹æ‡‰è©²æ˜¯åŸå­çš„ï¼ˆå…¨éƒ¨æˆåŠŸæˆ–å…¨éƒ¨å¤±æ•—ï¼‰
   - åœ¨æ“ä½œå¯èƒ½å¤±æ•—æ™‚ï¼Œå…ˆä¿å­˜åŸå§‹ç‹€æ…‹
   - å¤±æ•—æ™‚å›æ»¾åˆ°åŸå§‹ç‹€æ…‹

2. **éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸**
   - æ°¸é ä¸è¦éœé»˜å¤±æ•—
   - æä¾›å…·é«”ã€å¯æ“ä½œçš„éŒ¯èª¤è¨Šæ¯
   - è¨˜éŒ„è©³ç´°éŒ¯èª¤ç”¨æ–¼èª¿è©¦ï¼Œé¡¯ç¤ºç°¡æ½”è¨Šæ¯çµ¦ç”¨æˆ¶

3. **ç”¨æˆ¶é«”é©—**
   - éŒ¯èª¤è¨Šæ¯æ‡‰è©²è§£é‡‹**ç‚ºä»€éº¼**å¤±æ•—
   - æä¾›**å¦‚ä½•**ä¿®å¾©çš„æŒ‡å¼•
   - é¿å…æŠ€è¡“è¡“èªï¼Œä½¿ç”¨ç”¨æˆ¶èƒ½ç†è§£çš„èªè¨€

4. **ç‹€æ…‹ç®¡ç†**
   - åœ¨æœ‰ç‹€æ…‹çš„ç³»çµ±ä¸­ï¼ˆå¦‚ Streamlitï¼‰ï¼Œæ˜ç¢ºç®¡ç†ç‹€æ…‹è½‰æ›
   - è€ƒæ…®éŒ¯èª¤æƒ…æ³ä¸‹çš„ç‹€æ…‹ä¸€è‡´æ€§
   - ä½¿ç”¨é˜²ç¦¦æ€§ç·¨ç¨‹é¿å…ç‹€æ…‹æå£

### ç¸½çµ

#### æ ¸å¿ƒå•é¡Œ
ç¼ºå°‘éŒ¯èª¤è™•ç†å’Œå›æ»¾æ©Ÿåˆ¶ï¼Œå°è‡´å¤±æ•—æ™‚è¨Šæ¯ä»è¢«æ·»åŠ åˆ°åˆ—è¡¨ï¼Œç”¨æˆ¶é‡è©¦æ™‚ç”¢ç”Ÿé‡è¤‡è¨Šæ¯ã€‚

#### è§£æ±ºæ–¹æ¡ˆ
1. âœ… åœ¨ `execute_chat()` ä¸­æ·»åŠ  try-except å’Œå›æ»¾æ©Ÿåˆ¶
2. âœ… åœ¨ UI å±¤æ·»åŠ éŒ¯èª¤æ•ç²å’Œé¡¯ç¤º
3. âœ… æä¾›å…·é«”ã€å¯æ“ä½œçš„éŒ¯èª¤è¨Šæ¯

#### çµæœ
âœ… è¨Šæ¯ä¸å†é‡è¤‡å‡ºç¾
âœ… ç”¨æˆ¶çœ‹åˆ°å…·é«”éŒ¯èª¤åŸå› 
âœ… å¯ä»¥æ ¹æ“šéŒ¯èª¤è¨Šæ¯æ¡å–é©ç•¶è¡Œå‹•
âœ… ç³»çµ±ç‹€æ…‹ä¿æŒä¸€è‡´

#### å¯¦éš›å¤±æ•—åŸå› ï¼ˆæ¨æ¸¬ï¼‰
åŸºæ–¼ 132.1K tokens çš„ä¸Šä¸‹æ–‡å¤§å°ï¼Œæœ€å¯èƒ½æ˜¯ï¼š
- ä¸Šä¸‹æ–‡é•·åº¦è¶…å‡ºæ¨¡å‹é™åˆ¶ï¼ˆgpt-oss:20b å¯èƒ½æœ‰ 8K-32K token é™åˆ¶ï¼‰
- Ollama è¨˜æ†¶é«”ä¸è¶³è™•ç†å¦‚æ­¤å¤§çš„ä¸Šä¸‹æ–‡
- è«‹æ±‚è™•ç†è¶…æ™‚

#### å»ºè­°ä¸‹ä¸€æ­¥
1. ä½¿ç”¨è€…æ‡‰è©²æ¸›å°‘ä¸Šä¸‹æ–‡ä¸­çš„ sources æˆ– notes æ•¸é‡
2. è€ƒæ…®å¯¦æ–½ä¸Šä¸‹æ–‡å¤§å°è­¦å‘Šæ©Ÿåˆ¶
3. å¯é¸ï¼šæ·»åŠ è‡ªå‹•ä¸Šä¸‹æ–‡ä¿®å‰ªåŠŸèƒ½

---

**æ–‡ä»¶ç‰ˆæœ¬ï¼š** 1.5
**æœ€å¾Œæ›´æ–°ï¼š** 2025-10-20 16:00
**ä½œè€…ï¼š** Claude (Anthropic)
**å°ˆæ¡ˆç‰ˆæœ¬ï¼š** Open Notebook 0.3.3
**æ–°å¢ç« ç¯€ï¼š** å•é¡Œ 8 - èŠå¤©è¨Šæ¯é‡è¤‡æäº¤èˆ‡éŒ¯èª¤è™•ç†æ”¹é€²

## å•é¡Œ 8 é‡è¦æ›´æ–°ï¼šçœŸæ­£åŸå› æ˜¯ Streamlit é é¢é‡æ–°é‹è¡Œ

### ä½¿ç”¨è€…æ¾„æ¸…

**é‡è¦åé¥‹ï¼š** "I did not send multiple query 'give me a summary of the book', I just send once"

é€™å®Œå…¨æ”¹è®Šäº†å•é¡Œåˆ†æï¼ä½¿ç”¨è€…**åªç™¼é€ä¸€æ¬¡**ï¼Œå»çœ‹åˆ° 7 å€‹é‡è¤‡è¨Šæ¯ â†’ é€™ä¸æ˜¯ç”¨æˆ¶é‡è©¦ï¼Œè€Œæ˜¯ **Streamlit è‡ªå‹•é‡æ–°é‹è¡Œ**å°è‡´çš„é‡è¤‡è™•ç†ã€‚

### çœŸæ­£çš„æ ¹æœ¬åŸå› ï¼šStreamlit é‡æ–°é‹è¡Œé™·é˜±

**Streamlit æ©Ÿåˆ¶ï¼š**
- æ¯æ¬¡ç‹€æ…‹æ”¹è®Š â†’ æ•´å€‹è…³æœ¬é‡æ–°é‹è¡Œ
- `st.chat_input()` å¯èƒ½åœ¨é‡æ–°é‹è¡Œæ™‚ä¿ç•™ä¸Šæ¬¡çš„å€¼
- æ²’æœ‰é˜²é‡è¤‡æ©Ÿåˆ¶ â†’ åŒä¸€è«‹æ±‚è¢«è™•ç†å¤šæ¬¡

**é‡è¤‡ç™¼ç”Ÿæµç¨‹ï¼š**
```
é‹è¡Œ 1: ç”¨æˆ¶è¼¸å…¥ â†’ execute_chat() â†’ æ·»åŠ è¨Šæ¯ â†’ ä¿®æ”¹ state â†’ è§¸ç™¼é‡æ–°é‹è¡Œ
é‹è¡Œ 2: request ä»æœ‰å€¼ â†’ execute_chat() â†’ å†æ¬¡æ·»åŠ  â†’ è§¸ç™¼é‡æ–°é‹è¡Œ
é‹è¡Œ 3-7: æŒçºŒé‡è¤‡...
çµæœ: [msg, msg, msg, msg, msg, msg, msg]
```

### æ–°çš„ä¿®å¾©æ–¹æ¡ˆï¼šé˜²é‡è¤‡è™•ç†æ©Ÿåˆ¶

**ä½ç½®ï¼š** [pages/stream_app/chat.py:240-259](pages/stream_app/chat.py#L240-L259)

```python
request = st.chat_input("Enter your question")
if request:
    # âœ… æ–°å¢ï¼šé˜²é‡è¤‡è™•ç†
    last_request_key = f"{current_session.id}_last_request"
    if last_request_key not in st.session_state:
        st.session_state[last_request_key] = None

    # âœ… åªè™•ç†æ–°è«‹æ±‚
    if st.session_state[last_request_key] != request:
        st.session_state[last_request_key] = request
        try:
            response = execute_chat(...)
            st.session_state[current_session.id]["messages"] = response["messages"]
        except Exception as e:
            st.error(f"âŒ {str(e)}")
```

**é˜²é‡è¤‡é‚è¼¯ï¼š**
1. è¿½è¹¤æœ€å¾Œè™•ç†çš„è«‹æ±‚ (`last_request`)
2. æ¯”è¼ƒæ–°è«‹æ±‚èˆ‡ä¸Šæ¬¡è«‹æ±‚
3. åªæœ‰ä¸åŒæ™‚æ‰è™•ç†
4. ç«‹å³æ›´æ–°è¿½è¹¤å€¼ï¼Œé˜²æ­¢é‡è¤‡

### ä¿®å¾©æ•ˆæœ

**ä¿®å¾©å‰ï¼š**
```
ç”¨æˆ¶ç™¼é€ 1 æ¬¡
â†’ è™•ç† â†’ ç‹€æ…‹æ”¹è®Š â†’ é‡æ–°é‹è¡Œ
â†’ å†æ¬¡è™•ç†ï¼ˆrequest ä¿ç•™ï¼‰â†’ ç‹€æ…‹æ”¹è®Š â†’ é‡æ–°é‹è¡Œ
â†’ é‡è¤‡ 7 æ¬¡ â†’ 7 å€‹è¨Šæ¯
```

**ä¿®å¾©å¾Œï¼š**
```
ç”¨æˆ¶ç™¼é€ 1 æ¬¡
â†’ last_request: None â†’ "give..." (ä¸åŒ)
â†’ è™•ç† â†’ ç‹€æ…‹æ”¹è®Š â†’ é‡æ–°é‹è¡Œ
â†’ last_request: "give..." â†’ "give..." (ç›¸åŒ)
â†’ è·³éï¼âœ…
â†’ åªæœ‰ 1 å€‹è¨Šæ¯ âœ…
```

### ç‚ºä»€éº¼éœ€è¦å…©å±¤ä¿è­·

**1. UI å±¤é˜²é‡è¤‡**ï¼ˆæ–°å¢ï¼‰
- é˜²æ­¢ Streamlit é‡æ–°é‹è¡Œæ™‚çš„é‡è¤‡è™•ç†
- ä½¿ç”¨ `last_request` è¿½è¹¤
- é‡å°**æˆåŠŸåŸ·è¡Œ**å ´æ™¯

**2. åŸ·è¡Œå±¤å›æ»¾**ï¼ˆä¹‹å‰å·²æ·»åŠ ï¼‰
- é˜²æ­¢éŒ¯èª¤æ™‚è¨Šæ¯æ®˜ç•™
- ä½¿ç”¨ `original_messages` å›æ»¾
- é‡å°**å¤±æ•—åŸ·è¡Œ**å ´æ™¯

**å…©è€…éƒ½å¿…è¦**ï¼Œé‡å°ä¸åŒå ´æ™¯ï¼

### Streamlit æœ€ä½³å¯¦è¸

**é˜²é‡è¤‡åŸ·è¡Œæ¨¡å¼ï¼š**
```python
# æ¨¡å¼ 1ï¼šState è¿½è¹¤ï¼ˆæˆ‘å€‘ä½¿ç”¨çš„ï¼‰
if st.session_state.get("last_value") != current_value:
    st.session_state["last_value"] = current_value
    process()

# æ¨¡å¼ 2ï¼šForm + Submit
with st.form("form"):
    value = st.text_input()
    if st.form_submit_button():
        process(value)
```

### é‡è¦ç™¼ç¾

æ„Ÿè¬ä½¿ç”¨è€…æ¾„æ¸…ï¼è®“æˆ‘å€‘ç™¼ç¾çœŸæ­£å•é¡Œï¼š
- âŒ ä¸æ˜¯ç”¨æˆ¶é‡è©¦å°è‡´é‡è¤‡
- âœ… æ˜¯ Streamlit é‡æ–°é‹è¡Œæ©Ÿåˆ¶å°è‡´
- âœ… éœ€è¦ UI å±¤é˜²é‡è¤‡ + åŸ·è¡Œå±¤å›æ»¾

---

## å•é¡Œ 9ï¼šSurrealDB ç«¯å£æœªæš´éœ²å°è‡´èŠå¤©åŠŸèƒ½å®Œå…¨å¤±æ•—

### å•é¡Œæè¿°

**å ±å‘Šæ™‚é–“ï¼š** 2025-10-20 16:58

**ä½¿ç”¨è€…åé¥‹ï¼š**
> "I use smaller model, and also use short paper, but it still show 'fail to send message'"

ä½¿ç”¨è€…å˜—è©¦ï¼š
- ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆé¿å…ä¸Šä¸‹æ–‡é•·åº¦å•é¡Œï¼‰
- ä½¿ç”¨è¼ƒçŸ­çš„æ–‡ä»¶ï¼ˆé¿å…ä¸Šä¸‹æ–‡éå¤§ï¼‰
- **ä»ç„¶å‡ºç¾ "Failed to send message" éŒ¯èª¤**

### æ ¹æœ¬åŸå› 

**ğŸ”´ åš´é‡æ€§ï¼šCritical - ç³»çµ±åŸºç¤è¨­æ–½å•é¡Œ**

**å•é¡Œï¼š** SurrealDB å®¹å™¨ç«¯å£æœªæ˜ å°„åˆ°ä¸»æ©Ÿ

**æŠ€è¡“ç´°ç¯€ï¼š**

1. **Docker Compose é…ç½®ç¼ºå¤±**ï¼š
   ```yaml
   # docker-compose.yml - åŸå§‹é…ç½®ï¼ˆéŒ¯èª¤ï¼‰
   services:
     surrealdb:
       image: surrealdb/surrealdb:v2
       volumes:
         - ./surreal_data:/mydata
       # âŒ ç¼ºå°‘ ports é…ç½®
   ```

2. **é€£ç·šå¤±æ•—æ—¥èªŒ**ï¼š
   ```
   ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 8000)
   ```
   - Worker å˜—è©¦é€£æ¥ `127.0.0.1:8000`
   - å®¹å™¨å…§ SurrealDB æ­£å¸¸é‹è¡Œ
   - ä¸»æ©Ÿç„¡æ³•è¨ªå•å®¹å™¨ç«¯å£ 8000

3. **å½±éŸ¿ç¯„åœ**ï¼š
   - âœ… Streamlit UI å¯ä»¥å•Ÿå‹•ï¼ˆä¸ç›´æ¥ä¾è³´ SurrealDBï¼‰
   - âœ… API å¯ä»¥å•Ÿå‹•ï¼ˆåˆå§‹åŒ–æ™‚ä¸å¼·åˆ¶é€£æ¥ï¼‰
   - âŒ Worker ç„¡æ³•é€£æ¥ SurrealDB
   - âŒ æ‰€æœ‰èŠå¤©åŠŸèƒ½å¤±æ•—ï¼ˆç„¡æ³•ä¿å­˜/è®€å–è¨Šæ¯ï¼‰
   - âŒ ç­†è¨˜æœ¬ã€ä¾†æºã€è½‰æ›åŠŸèƒ½å…¨éƒ¨å¤±æ•—

### è¨ºæ–·éç¨‹

#### æ­¥é©Ÿ 1ï¼šæª¢æŸ¥æœå‹™ç«¯å£

```bash
$ netstat -tlnp | grep -E "8502|5055|8000"
tcp    0.0.0.0:5055    0.0.0.0:*    LISTEN      -   # API âœ…
tcp    0.0.0.0:8502    0.0.0.0:*    LISTEN      -   # Streamlit âœ…
# âŒ æ²’æœ‰ 8000 ç«¯å£ï¼ˆSurrealDBï¼‰
```

#### æ­¥é©Ÿ 2ï¼šæª¢æŸ¥ SurrealDB å®¹å™¨

```bash
$ docker ps | grep surrealdb
lcj_open_notebook-surrealdb-1   Up 5 minutes   # å®¹å™¨é‹è¡Œä¸­ âœ…

$ docker port lcj_open_notebook-surrealdb-1
# âŒ æ²’æœ‰è¼¸å‡ºï¼ˆæ²’æœ‰ç«¯å£æ˜ å°„ï¼‰

$ curl http://localhost:8000/health
# âŒ é€£ç·šå¤±æ•—
```

#### æ­¥é©Ÿ 3ï¼šæª¢æŸ¥ Worker æ—¥èªŒ

```bash
$ tail -200 logs/worker.log | grep -i error
ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 8000)
```

#### æ­¥é©Ÿ 4ï¼šæª¢æŸ¥ docker-compose.yml

ç™¼ç¾ SurrealDB æœå‹™é…ç½®ä¸­ç¼ºå°‘ `ports` è¨­å®šã€‚

### è§£æ±ºæ–¹æ¡ˆ

#### ä¿®å¾© 1ï¼šæ›´æ–° docker-compose.yml

```yaml
# docker-compose.yml - ä¿®å¾©å¾Œ
services:
  surrealdb:
    image: surrealdb/surrealdb:v2
    ports:
      - "8000:8000"  # âœ… æ·»åŠ ç«¯å£æ˜ å°„
    volumes:
      - ./surreal_data:/mydata
    environment:
      - SURREAL_EXPERIMENTAL_GRAPHQL=true
    command: start --log info --user root --pass root rocksdb:/mydata/mydatabase.db
    pull_policy: always
    user: root
    restart: always
```

**è®Šæ›´ï¼š** æ·»åŠ  `ports: - "8000:8000"` é…ç½®

#### ä¿®å¾© 2ï¼šé‡æ–°å‰µå»ºå®¹å™¨

ç”±æ–¼é‡åˆ° Docker Registry 503 éŒ¯èª¤ï¼Œä½¿ç”¨ç›´æ¥å‘½ä»¤å‰µå»ºå®¹å™¨ï¼š

```bash
# åœæ­¢ä¸¦ç§»é™¤èˆŠå®¹å™¨
docker stop lcj_open_notebook-surrealdb-1
docker rm lcj_open_notebook-surrealdb-1

# ä½¿ç”¨æ­£ç¢ºé…ç½®é‡æ–°å‰µå»º
docker run -d \
  --name lcj_open_notebook-surrealdb-1 \
  -p 8000:8000 \
  -v "$(pwd)/surreal_data:/mydata" \
  --user root \
  -e SURREAL_EXPERIMENTAL_GRAPHQL=true \
  surrealdb/surrealdb:v2 \
  start --log info --user root --pass root rocksdb:/mydata/mydatabase.db
```

#### ä¿®å¾© 3ï¼šé©—è­‰é€£ç·š

```bash
$ curl http://localhost:8000/health
# âœ… æˆåŠŸï¼ˆè¿”å›ç©ºéŸ¿æ‡‰è¡¨ç¤ºå¥åº·æª¢æŸ¥é€šéï¼‰

$ docker logs lcj_open_notebook-surrealdb-1 | tail -3
INFO surrealdb::net: Started web server on 0.0.0.0:8000
# âœ… SurrealDB æ­£å¸¸å•Ÿå‹•ä¸¦ç›£è½ 8000
```

#### ä¿®å¾© 4ï¼šé‡å•Ÿ Worker

Worker éœ€è¦é‡å•Ÿä»¥é‡æ–°é€£æ¥è³‡æ–™åº«ï¼š

```bash
# åœæ­¢èˆŠ Workerï¼ˆéƒ¨åˆ†å¯èƒ½éœ€è¦ sudoï¼‰
pkill -f "surreal-commands-worker"

# å•Ÿå‹•æ–° Worker
nohup uv run --env-file .env surreal-commands-worker --import-modules commands > logs/worker.log 2>&1 &

# é©—è­‰å•Ÿå‹•
tail -10 logs/worker.log
# âœ… é¡¯ç¤º "Starting LIVE query listener for new commands..."
```

### é©—è­‰çµæœ

**æœ€çµ‚æœå‹™ç‹€æ…‹ï¼š**

```bash
=== æœå‹™ç‹€æ…‹ ===

SurrealDB (port 8000):
  âœ… Running

API (port 5055):
  âœ… Running

Worker:
  âœ… Running

Streamlit (port 8502):
  âœ… Running
```

**æ‰€æœ‰æœå‹™æ­£å¸¸é‹è¡Œï¼ŒèŠå¤©åŠŸèƒ½æ‡‰è©²å¯ä»¥æ­£å¸¸å·¥ä½œã€‚**

### ç‚ºä»€éº¼å…ˆå‰çš„ä¿®å¾©ï¼ˆå•é¡Œ 8ï¼‰æ²’æœ‰è§£æ±ºå•é¡Œ

**å…ˆå‰è¨ºæ–·ï¼ˆå•é¡Œ 8ï¼‰ï¼š**
- âœ… æ­£ç¢ºï¼šä¸Šä¸‹æ–‡éå¤§ï¼ˆ132.1K tokensï¼‰
- âœ… æ­£ç¢ºï¼šéœ€è¦éŒ¯èª¤è™•ç†å’Œå›æ»¾æ©Ÿåˆ¶
- âœ… æ­£ç¢ºï¼šéœ€è¦é˜²é‡è¤‡æ©Ÿåˆ¶
- âŒ **ä½†æ²’æœ‰ç™¼ç¾åº•å±¤åŸºç¤è¨­æ–½å•é¡Œ**

**å¯¦éš›æƒ…æ³ï¼š**
1. ä½¿ç”¨è€…åˆ‡æ›åˆ°å°æ¨¡å‹å’ŒçŸ­æ–‡ä»¶ï¼ˆè§£æ±ºä¸Šä¸‹æ–‡å•é¡Œï¼‰ âœ…
2. éŒ¯èª¤è™•ç†å’Œé˜²é‡è¤‡å·²å¯¦ä½œï¼ˆè§£æ±ºè¨Šæ¯è™•ç†å•é¡Œï¼‰ âœ…
3. **ä½† SurrealDB æ ¹æœ¬ç„¡æ³•é€£æ¥ï¼ˆæ–°ç™¼ç¾çš„å•é¡Œï¼‰** âŒ

**å•é¡Œå±¤æ¬¡ï¼š**
```
æ‡‰ç”¨å±¤å•é¡Œï¼ˆå•é¡Œ 8ï¼‰:
â”œâ”€â”€ ä¸Šä¸‹æ–‡éå¤§ âœ… å·²è§£æ±ºï¼ˆä½¿ç”¨å°æ¨¡å‹/çŸ­æ–‡ä»¶ï¼‰
â”œâ”€â”€ éŒ¯èª¤è™•ç†ç¼ºå¤± âœ… å·²è§£æ±ºï¼ˆæ·»åŠ å›æ»¾æ©Ÿåˆ¶ï¼‰
â””â”€â”€ è¨Šæ¯é‡è¤‡ âœ… å·²è§£æ±ºï¼ˆé˜²é‡è¤‡æ©Ÿåˆ¶ï¼‰

åŸºç¤è¨­æ–½å•é¡Œï¼ˆå•é¡Œ 9ï¼‰:
â””â”€â”€ SurrealDB ç«¯å£æœªæš´éœ² âœ… æœ¬æ¬¡è§£æ±º
```

é€™è§£é‡‹äº†ç‚ºä»€éº¼ä½¿ç”¨è€…åšäº†æ‰€æœ‰å»ºè­°çš„æ›´æ”¹å¾Œä»ç„¶é‡åˆ°éŒ¯èª¤ã€‚

### å½±éŸ¿åˆ†æ

**å½±éŸ¿ç¨‹åº¦ï¼š** ğŸ”´ Critical

**å½±éŸ¿æ™‚é–“ï¼š** å¾ç³»çµ±é¦–æ¬¡å•Ÿå‹•é–‹å§‹ï¼ˆæœªçŸ¥å…·é«”æ™‚é–“ï¼‰

**å—å½±éŸ¿åŠŸèƒ½ï¼š**
- âŒ æ‰€æœ‰èŠå¤©åŠŸèƒ½
- âŒ ç­†è¨˜æœ¬ç®¡ç†
- âŒ ä¾†æºç®¡ç†
- âŒ ç­†è¨˜ç®¡ç†
- âŒ è½‰æ›å·¥ä½œæµ
- âŒ åµŒå…¥å’Œæœç´¢åŠŸèƒ½

**æœªå—å½±éŸ¿ï¼š**
- âœ… UI æ¸²æŸ“ï¼ˆStreamlit å‰ç«¯ï¼‰
- âœ… API å•Ÿå‹•ï¼ˆä½†åŠŸèƒ½ç„¡æ³•é‹ä½œï¼‰

### é é˜²æªæ–½

#### 1. å•Ÿå‹•è…³æœ¬å¥åº·æª¢æŸ¥

**æ›´æ–° `start_system_improved.sh`** æ·»åŠ  SurrealDB é€£ç·šé©—è­‰ï¼š

```bash
# æª¢æŸ¥ SurrealDB ç«¯å£
if check_port 8000; then
    echo "âœ… SurrealDB port 8000 accessible"

    # é©—è­‰å¥åº·æª¢æŸ¥
    if curl -s http://localhost:8000/health > /dev/null 2>&1; then
        echo "âœ… SurrealDB health check passed"
    else
        echo "âš ï¸  SurrealDB port open but health check failed"
    fi
else
    echo "âŒ SurrealDB port 8000 not accessible"
    echo "   Please check docker-compose.yml ports configuration"
    exit 1
fi
```

#### 2. Docker Compose é©—è­‰

**åœ¨æ–‡ä»¶ä¸­æ·»åŠ è¨»é‡‹è­¦å‘Šï¼š**

```yaml
services:
  surrealdb:
    image: surrealdb/surrealdb:v2
    ports:
      - "8000:8000"  # âš ï¸ REQUIRED: Must expose port for local development
    # ...
```

#### 3. éŒ¯èª¤è¨Šæ¯æ”¹é€²

**æ›´æ–° Worker é€£ç·šéŒ¯èª¤è¨Šæ¯** æä¾›è¨ºæ–·æŒ‡å¼•ï¼š

```python
except ConnectionRefusedError:
    logger.error(
        "Failed to connect to SurrealDB at 127.0.0.1:8000\n"
        "Possible causes:\n"
        "  1. SurrealDB container not running\n"
        "  2. Port 8000 not exposed in docker-compose.yml\n"
        "  3. SurrealDB still starting up\n"
        "Run: docker ps | grep surrealdb\n"
        "Run: curl http://localhost:8000/health"
    )
```

#### 4. ç³»çµ±ç‹€æ…‹æª¢æŸ¥æŒ‡ä»¤

**æ·»åŠ åˆ° Makefile**ï¼š

```makefile
health-check:
	@echo "ğŸ” Checking Open Notebook services..."
	@echo "SurrealDB:"
	@curl -s http://localhost:8000/health && echo "  âœ… Healthy" || echo "  âŒ Unhealthy"
	@echo "API:"
	@curl -s http://localhost:5055/health && echo "  âœ… Healthy" || echo "  âŒ Unhealthy"
	@echo "Streamlit:"
	@pgrep -f "streamlit" > /dev/null && echo "  âœ… Running" || echo "  âŒ Not running"
```

### å­¸ç¿’è¦é»

#### æŠ€è¡“å±¤é¢

1. **å®¹å™¨ç«¯å£æ˜ å°„ä¸æœƒç¹¼æ‰¿æˆ–è‡ªå‹•é…ç½®**
   - Docker Compose ä¸­çš„ `ports` å¿…é ˆæ˜ç¢ºæŒ‡å®š
   - å®¹å™¨å…§éƒ¨æœå‹™å¯ä»¥æ­£å¸¸é‹è¡Œï¼Œä½†ä¸»æ©Ÿç„¡æ³•è¨ªå•

2. **æ‡‰ç”¨å±¤éŒ¯èª¤å¯èƒ½æ©è“‹åŸºç¤è¨­æ–½å•é¡Œ**
   - å…ˆå‰å°ˆæ³¨æ–¼æ‡‰ç”¨é‚è¼¯ï¼ˆä¸Šä¸‹æ–‡é•·åº¦ã€éŒ¯èª¤è™•ç†ï¼‰
   - å¿½ç•¥äº†åº•å±¤é€£ç·šå¤±æ•—çš„æ ¹æœ¬åŸå› 

3. **å¤šå±¤è¨ºæ–·çš„é‡è¦æ€§**
   - æ‡‰ç”¨å±¤ â†’ ç¶²è·¯å±¤ â†’ åŸºç¤è¨­æ–½å±¤
   - å¾æ—¥èªŒéŒ¯èª¤è¿½æº¯åˆ°ç³»çµ±é…ç½®

#### æµç¨‹æ”¹é€²

1. **ç³»çµ±å•Ÿå‹•é©—è­‰æ¸…å–®**ï¼š
   ```
   â˜ SurrealDB å®¹å™¨é‹è¡Œ
   â˜ SurrealDB ç«¯å£å¯è¨ªå•
   â˜ SurrealDB å¥åº·æª¢æŸ¥é€šé
   â˜ API æœå‹™å•Ÿå‹•
   â˜ Worker é€£æ¥æˆåŠŸ
   â˜ Streamlit UI å¯è¨ªå•
   ```

2. **åˆ†å±¤é™¤éŒ¯æµç¨‹**ï¼š
   ```
   éŒ¯èª¤ç™¼ç”Ÿ â†’ æª¢æŸ¥æ—¥èªŒ
   â†“
   é€£ç·šéŒ¯èª¤ï¼Ÿâ†’ æª¢æŸ¥ç«¯å£
   â†“
   ç«¯å£é–‹æ”¾ï¼Ÿâ†’ æª¢æŸ¥å®¹å™¨é…ç½®
   â†“
   é…ç½®æ­£ç¢ºï¼Ÿâ†’ æª¢æŸ¥ç¶²è·¯
   ```

3. **å®Œæ•´æ€§æ¸¬è©¦**ï¼š
   - ä¸åƒ…æ¸¬è©¦æœå‹™å•Ÿå‹•
   - é‚„è¦æ¸¬è©¦æœå‹™é–“é€£ç·š
   - ç«¯åˆ°ç«¯åŠŸèƒ½é©—è­‰

### ç›¸é—œå•é¡Œ

- **å•é¡Œ 4**ï¼šstart_system.sh åˆ†æï¼ˆå•Ÿå‹•è…³æœ¬æ”¹é€²ï¼‰
- **å•é¡Œ 8**ï¼šèŠå¤©è¨Šæ¯é‡è¤‡æäº¤ï¼ˆæ‡‰ç”¨å±¤éŒ¯èª¤è™•ç†ï¼‰
- **å•é¡Œ 3**ï¼šWorker å•Ÿå‹•å¤±æ•—ï¼ˆç’°å¢ƒé…ç½®ï¼‰

**å€åˆ¥ï¼š**
- å•é¡Œ 3 æ˜¯ç’°å¢ƒè®Šæ•¸é…ç½®éŒ¯èª¤ï¼ˆæ‡‰ç”¨å±¤ï¼‰
- å•é¡Œ 9 æ˜¯åŸºç¤è¨­æ–½é…ç½®ç¼ºå¤±ï¼ˆç¶²è·¯å±¤ï¼‰

### ä¿®å¾©æ–‡ä»¶

- `docker-compose.yml` - æ·»åŠ  SurrealDB ç«¯å£æ˜ å°„
- è¨ˆåŠƒæ›´æ–° `start_system_improved.sh` - æ·»åŠ å¥åº·æª¢æŸ¥ï¼ˆå¾…å¯¦ä½œï¼‰

---

**æ–‡ä»¶ç‰ˆæœ¬ï¼š** 1.7
**æœ€å¾Œæ›´æ–°ï¼š** 2025-10-20 17:05
**é‡è¦æ›´æ–°ï¼š**
- å•é¡Œ 9 - SurrealDB ç«¯å£æœªæš´éœ²å°è‡´æ‰€æœ‰è³‡æ–™åº«åŠŸèƒ½å¤±æ•—
- è­˜åˆ¥ç‚ºåŸºç¤è¨­æ–½å±¤å•é¡Œï¼Œèˆ‡å…ˆå‰æ‡‰ç”¨å±¤å•é¡Œï¼ˆå•é¡Œ 8ï¼‰äº’è£œ
